{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import initializer\n",
    "import kernel_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n",
      "[]\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "from django.db.models import Sum, Q\n",
    "from datetime import timedelta, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from purchasing.models import *\n",
    "from purchasing.serializers import *\n",
    "\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print([x.name for x in device_lib.list_local_devices()])\n",
    "print([gpu for gpu in tf.config.experimental.list_physical_devices('GPU')])\n",
    "print(tf.config.get_visible_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1405\n",
      "Validation samples: 351\n"
     ]
    }
   ],
   "source": [
    "# query requested dates and total daily costs\n",
    "qs = Purchase.objects.filter(~Q(requested=None)).values('requested').order_by('requested').annotate(daily_total=Sum('total_cost'))\n",
    "\n",
    "# extract daily total costs values\n",
    "dtc = [float(row['daily_total']) for row in qs]\n",
    "dates = [d['requested'] for d in qs]\n",
    "\n",
    "# sum each value n with sum(n-1) values\n",
    "dt = []\n",
    "running_total = 0\n",
    "for i in range(len(dtc)):\n",
    "    running_total += dtc[i]\n",
    "    dt.append(running_total)\n",
    "\n",
    "\n",
    "# normalize between 0 --> 1\n",
    "#dt_norm = (dt - np.min(dt)) / (np.max(dt) - np.min(dt))\n",
    "\n",
    "# split into training/validation datasets\n",
    "split = int(len(dt) * 0.8)\n",
    "\n",
    "dt_train = dt[:split]\n",
    "dt_val = dt[split:-1]\n",
    "\n",
    "print(f\"Training samples: {len(dt_train)}\")\n",
    "print(f\"Validation samples: {len(dt_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape= (1375, 1, 30)  y shape= (1375,)\n",
      "x shape= (321, 1, 30)  y shape= (321,)\n"
     ]
    }
   ],
   "source": [
    "WINDOW = 30  # look-back\n",
    "HORIZON = 1  # look-forward\n",
    "\n",
    "def create_sequences(data, window, horizon):\n",
    "    \"\"\"\n",
    "    Generate data sequences.\n",
    "    \"\"\"\n",
    "    x, y = [], []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        x_end = i + window\n",
    "\n",
    "        if x_end > len(data) - 1:\n",
    "            break\n",
    "\n",
    "        x.append(data[i:x_end])\n",
    "        y.append(data[x_end])\n",
    "    \n",
    "    x = np.expand_dims(x, axis=1)\n",
    "\n",
    "    print(f\"x shape= {np.shape(x)}  y shape= {np.shape(y)}\")\n",
    "    return x, np.asarray(y)\n",
    "\n",
    "x_train, y_train = create_sequences(dt_train, WINDOW, HORIZON)\n",
    "x_val, y_val = create_sequences(dt_val, WINDOW, HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add checkpoint callback\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    './purchase_lstm_forecast_model.h5',\n",
    "    verbose=0,\n",
    "    save_best=True,\n",
    "    save_weights_only=False,\n",
    "    save_best_only=True,\n",
    "    mode='min'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 128)               81408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81,537\n",
      "Trainable params: 81,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "43/43 [==============================] - 2s 11ms/step - loss: 1893163.6250 - mae: 1893163.6250 - mse: 6324665974784.0000 - val_loss: 162593.2344 - val_mae: 162593.2344 - val_mse: 26880759808.0000\n",
      "Epoch 2/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 83260.6641 - mae: 83260.6641 - mse: 16615535616.0000 - val_loss: 16995.8066 - val_mae: 16995.8066 - val_mse: 748720192.0000\n",
      "Epoch 3/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 37265.6562 - mae: 37265.6562 - mse: 6906498048.0000 - val_loss: 12113.8848 - val_mae: 12113.8848 - val_mse: 488056224.0000\n",
      "Epoch 4/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 36897.7539 - mae: 36897.7539 - mse: 5749420544.0000 - val_loss: 43392.7773 - val_mae: 43392.7773 - val_mse: 2056526976.0000\n",
      "Epoch 5/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 36660.4141 - mae: 36660.4141 - mse: 5317502976.0000 - val_loss: 13689.2744 - val_mae: 13689.2744 - val_mse: 456558496.0000\n",
      "Epoch 6/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 34565.5664 - mae: 34565.5664 - mse: 4684190720.0000 - val_loss: 26039.8457 - val_mae: 26039.8457 - val_mse: 747541568.0000\n",
      "Epoch 7/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 34312.7969 - mae: 34312.7969 - mse: 4369939968.0000 - val_loss: 17057.3867 - val_mae: 17057.3867 - val_mse: 736154176.0000\n",
      "Epoch 8/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 35608.7383 - mae: 35608.7383 - mse: 4513301504.0000 - val_loss: 12832.5713 - val_mae: 12832.5713 - val_mse: 452467552.0000\n",
      "Epoch 9/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 35414.4375 - mae: 35414.4375 - mse: 4594427392.0000 - val_loss: 16703.4727 - val_mae: 16703.4727 - val_mse: 457141216.0000\n",
      "Epoch 10/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 33698.5859 - mae: 33698.5859 - mse: 4321277440.0000 - val_loss: 64153.8320 - val_mae: 64153.8320 - val_mse: 4516263936.0000\n",
      "Epoch 11/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 35204.4219 - mae: 35204.4219 - mse: 4247155968.0000 - val_loss: 40296.1055 - val_mae: 40296.1055 - val_mse: 1763902464.0000\n",
      "Epoch 12/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 32168.7383 - mae: 32168.7383 - mse: 4129829120.0000 - val_loss: 39203.8242 - val_mae: 39203.8242 - val_mse: 1666459520.0000\n",
      "Epoch 13/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 38412.2500 - mae: 38412.2500 - mse: 4418225152.0000 - val_loss: 17794.2910 - val_mae: 17794.2910 - val_mse: 464190368.0000\n",
      "Epoch 14/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 31061.5234 - mae: 31061.5234 - mse: 3853603840.0000 - val_loss: 21196.5684 - val_mae: 21196.5684 - val_mse: 546013568.0000\n",
      "Epoch 15/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 38078.7266 - mae: 38078.7266 - mse: 4432365568.0000 - val_loss: 38240.6914 - val_mae: 38240.6914 - val_mse: 1582998016.0000\n",
      "Epoch 16/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 35510.0977 - mae: 35510.0977 - mse: 4024237824.0000 - val_loss: 36406.1055 - val_mae: 36406.1055 - val_mse: 1739361408.0000\n",
      "Epoch 17/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 37363.0000 - mae: 37363.0000 - mse: 4180760320.0000 - val_loss: 11082.8662 - val_mae: 11082.8662 - val_mse: 456799392.0000\n",
      "Epoch 18/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 35370.2617 - mae: 35370.2617 - mse: 4014688000.0000 - val_loss: 24527.3672 - val_mae: 24527.3672 - val_mse: 669745216.0000\n",
      "Epoch 19/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 31442.6074 - mae: 31442.6074 - mse: 3604680448.0000 - val_loss: 47991.5703 - val_mae: 47991.5703 - val_mse: 2520589568.0000\n",
      "Epoch 20/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 32421.9297 - mae: 32421.9297 - mse: 3811257600.0000 - val_loss: 29041.4961 - val_mae: 29041.4961 - val_mse: 907171776.0000\n",
      "Epoch 21/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 36241.6953 - mae: 36241.6953 - mse: 3826368512.0000 - val_loss: 25774.4980 - val_mae: 25774.4980 - val_mse: 727238976.0000\n",
      "Epoch 22/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 31902.0762 - mae: 31902.0762 - mse: 3566529536.0000 - val_loss: 12263.1562 - val_mae: 12263.1562 - val_mse: 407055776.0000\n",
      "Epoch 23/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 32511.1758 - mae: 32511.1758 - mse: 3550655744.0000 - val_loss: 54946.7539 - val_mae: 54946.7539 - val_mse: 3307706368.0000\n",
      "Epoch 24/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 35076.2148 - mae: 35076.2148 - mse: 3850848768.0000 - val_loss: 71038.4062 - val_mae: 71038.4062 - val_mse: 5448008704.0000\n",
      "Epoch 25/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 32876.3633 - mae: 32876.3633 - mse: 3564101120.0000 - val_loss: 27988.8281 - val_mae: 27988.8281 - val_mse: 844968896.0000\n",
      "Epoch 26/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 33257.0820 - mae: 33257.0820 - mse: 3565102080.0000 - val_loss: 18251.1406 - val_mae: 18251.1406 - val_mse: 450288320.0000\n",
      "Epoch 27/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 30586.1816 - mae: 30586.1816 - mse: 3224973568.0000 - val_loss: 24293.7598 - val_mae: 24293.7598 - val_mse: 654390208.0000\n",
      "Epoch 28/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 30264.0410 - mae: 30264.0410 - mse: 3312665600.0000 - val_loss: 10629.3955 - val_mae: 10629.3955 - val_mse: 415013824.0000\n",
      "Epoch 29/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 30290.7695 - mae: 30290.7695 - mse: 3187500544.0000 - val_loss: 38586.1523 - val_mae: 38586.1523 - val_mse: 1865829760.0000\n",
      "Epoch 30/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 35233.5352 - mae: 35233.5352 - mse: 3480451072.0000 - val_loss: 21001.0684 - val_mae: 21001.0684 - val_mse: 522552736.0000\n",
      "Epoch 31/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 30794.0820 - mae: 30794.0820 - mse: 3289587200.0000 - val_loss: 12414.6133 - val_mae: 12414.6133 - val_mse: 378014784.0000\n",
      "Epoch 32/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 33886.4336 - mae: 33886.4336 - mse: 3255222272.0000 - val_loss: 15958.0137 - val_mae: 15958.0137 - val_mse: 627280448.0000\n",
      "Epoch 33/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 32580.9219 - mae: 32580.9219 - mse: 3157156608.0000 - val_loss: 18651.3887 - val_mae: 18651.3887 - val_mse: 450006528.0000\n",
      "Epoch 34/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 35655.0820 - mae: 35655.0820 - mse: 3453210112.0000 - val_loss: 68391.4688 - val_mae: 68391.4688 - val_mse: 5047285760.0000\n",
      "Epoch 35/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 31872.9336 - mae: 31872.9336 - mse: 3051881472.0000 - val_loss: 20213.3184 - val_mae: 20213.3184 - val_mse: 492601152.0000\n",
      "Epoch 36/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 28971.5645 - mae: 28971.5645 - mse: 2865125888.0000 - val_loss: 12000.1680 - val_mae: 12000.1680 - val_mse: 366540992.0000\n",
      "Epoch 37/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 33818.5781 - mae: 33818.5781 - mse: 3129354496.0000 - val_loss: 13205.8350 - val_mae: 13205.8350 - val_mse: 535648800.0000\n",
      "Epoch 38/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 28354.3848 - mae: 28354.3848 - mse: 2742864384.0000 - val_loss: 15404.0918 - val_mae: 15404.0918 - val_mse: 380841088.0000\n",
      "Epoch 39/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 29375.0801 - mae: 29375.0801 - mse: 2768055040.0000 - val_loss: 13967.8174 - val_mae: 13967.8174 - val_mse: 364031520.0000\n",
      "Epoch 40/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 30590.1152 - mae: 30590.1152 - mse: 2895619840.0000 - val_loss: 19042.9492 - val_mae: 19042.9492 - val_mse: 453103392.0000\n",
      "Epoch 41/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 29647.3223 - mae: 29647.3223 - mse: 2777109760.0000 - val_loss: 26586.6113 - val_mae: 26586.6113 - val_mse: 766054912.0000\n",
      "Epoch 42/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 33438.2266 - mae: 33438.2266 - mse: 3046624512.0000 - val_loss: 36333.3203 - val_mae: 36333.3203 - val_mse: 1420204416.0000\n",
      "Epoch 43/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 28690.9082 - mae: 28690.9082 - mse: 2584800000.0000 - val_loss: 23141.7734 - val_mae: 23141.7734 - val_mse: 597328704.0000\n",
      "Epoch 44/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27189.4395 - mae: 27189.4395 - mse: 2582268928.0000 - val_loss: 37452.5469 - val_mae: 37452.5469 - val_mse: 1510225536.0000\n",
      "Epoch 45/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 29111.5000 - mae: 29111.5000 - mse: 2648634624.0000 - val_loss: 34231.9688 - val_mae: 34231.9688 - val_mse: 1258196736.0000\n",
      "Epoch 46/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27616.1445 - mae: 27616.1445 - mse: 2608834304.0000 - val_loss: 43472.0547 - val_mae: 43472.0547 - val_mse: 2045590016.0000\n",
      "Epoch 47/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 31784.5898 - mae: 31784.5898 - mse: 2819751424.0000 - val_loss: 58350.0547 - val_mae: 58350.0547 - val_mse: 3736739072.0000\n",
      "Epoch 48/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 38904.6094 - mae: 38904.6094 - mse: 3414190080.0000 - val_loss: 54632.7461 - val_mae: 54632.7461 - val_mse: 3239131136.0000\n",
      "Epoch 49/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 32050.6348 - mae: 32050.6348 - mse: 2718742016.0000 - val_loss: 22821.4707 - val_mae: 22821.4707 - val_mse: 858647744.0000\n",
      "Epoch 50/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 34815.6289 - mae: 34815.6289 - mse: 2950705920.0000 - val_loss: 12255.4951 - val_mae: 12255.4951 - val_mse: 339818464.0000\n",
      "Epoch 51/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27330.8945 - mae: 27330.8945 - mse: 2409507840.0000 - val_loss: 18170.8496 - val_mae: 18170.8496 - val_mse: 665142400.0000\n",
      "Epoch 52/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 31000.6348 - mae: 31000.6348 - mse: 2648164864.0000 - val_loss: 29927.0723 - val_mae: 29927.0723 - val_mse: 961866240.0000\n",
      "Epoch 53/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 29806.3535 - mae: 29806.3535 - mse: 2524871424.0000 - val_loss: 45789.3086 - val_mae: 45789.3086 - val_mse: 2268489728.0000\n",
      "Epoch 54/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26804.4473 - mae: 26804.4473 - mse: 2373624576.0000 - val_loss: 11967.4424 - val_mae: 11967.4424 - val_mse: 332253696.0000\n",
      "Epoch 55/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26824.0996 - mae: 26824.0996 - mse: 2299110400.0000 - val_loss: 12112.9639 - val_mae: 12112.9639 - val_mse: 330563360.0000\n",
      "Epoch 56/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26481.8965 - mae: 26481.8965 - mse: 2264032768.0000 - val_loss: 28680.5195 - val_mae: 28680.5195 - val_mse: 884905792.0000\n",
      "Epoch 57/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 29526.7988 - mae: 29526.7988 - mse: 2506103040.0000 - val_loss: 30841.6270 - val_mae: 30841.6270 - val_mse: 1019067456.0000\n",
      "Epoch 58/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 38367.3594 - mae: 38367.3594 - mse: 3251803392.0000 - val_loss: 18263.2539 - val_mae: 18263.2539 - val_mse: 419353824.0000\n",
      "Epoch 59/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25744.8340 - mae: 25744.8340 - mse: 2238481920.0000 - val_loss: 36468.4727 - val_mae: 36468.4727 - val_mse: 1425296384.0000\n",
      "Epoch 60/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26132.8555 - mae: 26132.8555 - mse: 2155811840.0000 - val_loss: 9211.6416 - val_mae: 9211.6416 - val_mse: 358842368.0000\n",
      "Epoch 61/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 32902.4727 - mae: 32902.4727 - mse: 2578390784.0000 - val_loss: 11005.7285 - val_mae: 11005.7285 - val_mse: 320290144.0000\n",
      "Epoch 62/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 30679.1367 - mae: 30679.1367 - mse: 2455982336.0000 - val_loss: 16772.3496 - val_mae: 16772.3496 - val_mse: 379500320.0000\n",
      "Epoch 63/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26954.0879 - mae: 26954.0879 - mse: 2184660992.0000 - val_loss: 24828.4824 - val_mae: 24828.4824 - val_mse: 929365888.0000\n",
      "Epoch 64/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27288.9102 - mae: 27288.9102 - mse: 2272414208.0000 - val_loss: 10162.5547 - val_mae: 10162.5547 - val_mse: 319793440.0000\n",
      "Epoch 65/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 28977.7949 - mae: 28977.7949 - mse: 2347636992.0000 - val_loss: 41180.7070 - val_mae: 41180.7070 - val_mse: 1822841984.0000\n",
      "Epoch 66/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 35442.2148 - mae: 35442.2148 - mse: 2871943680.0000 - val_loss: 20896.9355 - val_mae: 20896.9355 - val_mse: 745457344.0000\n",
      "Epoch 67/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 29808.8125 - mae: 29808.8125 - mse: 2381895680.0000 - val_loss: 40383.2188 - val_mae: 40383.2188 - val_mse: 1935843584.0000\n",
      "Epoch 68/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 28614.5547 - mae: 28614.5547 - mse: 2312483072.0000 - val_loss: 21553.1699 - val_mae: 21553.1699 - val_mse: 525162848.0000\n",
      "Epoch 69/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27169.5508 - mae: 27169.5508 - mse: 2140553856.0000 - val_loss: 16271.2910 - val_mae: 16271.2910 - val_mse: 363123040.0000\n",
      "Epoch 70/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26101.9961 - mae: 26101.9961 - mse: 2059335424.0000 - val_loss: 12071.3213 - val_mae: 12071.3213 - val_mse: 449421856.0000\n",
      "Epoch 71/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24000.7773 - mae: 24000.7773 - mse: 1944540160.0000 - val_loss: 12133.4658 - val_mae: 12133.4658 - val_mse: 306132160.0000\n",
      "Epoch 72/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24488.7012 - mae: 24488.7012 - mse: 1897048576.0000 - val_loss: 27351.3340 - val_mae: 27351.3340 - val_mse: 804165952.0000\n",
      "Epoch 73/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24458.9727 - mae: 24458.9727 - mse: 1940586624.0000 - val_loss: 23639.9199 - val_mae: 23639.9199 - val_mse: 614672192.0000\n",
      "Epoch 74/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25622.8242 - mae: 25622.8242 - mse: 1960406016.0000 - val_loss: 30818.9902 - val_mae: 30818.9902 - val_mse: 1244109952.0000\n",
      "Epoch 75/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26646.1680 - mae: 26646.1680 - mse: 1998525568.0000 - val_loss: 17247.8496 - val_mae: 17247.8496 - val_mse: 381095040.0000\n",
      "Epoch 76/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26303.9355 - mae: 26303.9355 - mse: 1950090112.0000 - val_loss: 53901.8633 - val_mae: 53901.8633 - val_mse: 3128440832.0000\n",
      "Epoch 77/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27730.1680 - mae: 27730.1680 - mse: 2073396096.0000 - val_loss: 28748.1094 - val_mae: 28748.1094 - val_mse: 883946112.0000\n",
      "Epoch 78/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26487.6543 - mae: 26487.6543 - mse: 1961397632.0000 - val_loss: 44055.4883 - val_mae: 44055.4883 - val_mse: 2083863552.0000\n",
      "Epoch 79/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24354.4414 - mae: 24354.4414 - mse: 1809390848.0000 - val_loss: 9650.8896 - val_mae: 9650.8896 - val_mse: 294708640.0000\n",
      "Epoch 80/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 28179.5547 - mae: 28179.5547 - mse: 2083499392.0000 - val_loss: 29898.2090 - val_mae: 29898.2090 - val_mse: 954041024.0000\n",
      "Epoch 81/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24374.3594 - mae: 24374.3594 - mse: 1826439424.0000 - val_loss: 20863.6113 - val_mae: 20863.6113 - val_mse: 494655520.0000\n",
      "Epoch 82/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 32805.6250 - mae: 32805.6250 - mse: 2395677440.0000 - val_loss: 26605.7441 - val_mae: 26605.7441 - val_mse: 760891200.0000\n",
      "Epoch 83/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26860.6875 - mae: 26860.6875 - mse: 1862916352.0000 - val_loss: 35614.6680 - val_mae: 35614.6680 - val_mse: 1352581888.0000\n",
      "Epoch 84/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 30483.0898 - mae: 30483.0898 - mse: 2111578880.0000 - val_loss: 16721.6660 - val_mae: 16721.6660 - val_mse: 362751168.0000\n",
      "Epoch 85/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 22132.3223 - mae: 22132.3223 - mse: 1621471360.0000 - val_loss: 21798.9590 - val_mae: 21798.9590 - val_mse: 531437792.0000\n",
      "Epoch 86/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 28219.0781 - mae: 28219.0781 - mse: 1991162752.0000 - val_loss: 9806.6562 - val_mae: 9806.6562 - val_mse: 375322080.0000\n",
      "Epoch 87/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24149.8906 - mae: 24149.8906 - mse: 1726525696.0000 - val_loss: 11815.1963 - val_mae: 11815.1963 - val_mse: 283799424.0000\n",
      "Epoch 88/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23018.3848 - mae: 23018.3848 - mse: 1641582464.0000 - val_loss: 14003.1357 - val_mae: 14003.1357 - val_mse: 306014144.0000\n",
      "Epoch 89/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 27658.1504 - mae: 27658.1504 - mse: 1821421312.0000 - val_loss: 14556.0293 - val_mae: 14556.0293 - val_mse: 486871168.0000\n",
      "Epoch 90/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 27822.3457 - mae: 27822.3457 - mse: 1985338368.0000 - val_loss: 17245.3066 - val_mae: 17245.3066 - val_mse: 373114400.0000\n",
      "Epoch 91/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 26135.9336 - mae: 26135.9336 - mse: 1812001536.0000 - val_loss: 17507.3867 - val_mae: 17507.3867 - val_mse: 379931840.0000\n",
      "Epoch 92/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22078.3965 - mae: 22078.3965 - mse: 1542532224.0000 - val_loss: 31056.7969 - val_mae: 31056.7969 - val_mse: 1026731072.0000\n",
      "Epoch 93/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24171.1719 - mae: 24171.1719 - mse: 1662510592.0000 - val_loss: 48702.2305 - val_mae: 48702.2305 - val_mse: 2542697728.0000\n",
      "Epoch 94/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24296.0312 - mae: 24296.0312 - mse: 1680368640.0000 - val_loss: 22726.9395 - val_mae: 22726.9395 - val_mse: 568566016.0000\n",
      "Epoch 95/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25024.6113 - mae: 25024.6113 - mse: 1669612544.0000 - val_loss: 39817.3320 - val_mae: 39817.3320 - val_mse: 1850051840.0000\n",
      "Epoch 96/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22387.8633 - mae: 22387.8633 - mse: 1508429184.0000 - val_loss: 23574.7305 - val_mae: 23574.7305 - val_mse: 605967168.0000\n",
      "Epoch 97/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24744.9551 - mae: 24744.9551 - mse: 1650677504.0000 - val_loss: 9855.5547 - val_mae: 9855.5547 - val_mse: 266953520.0000\n",
      "Epoch 98/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23575.0098 - mae: 23575.0098 - mse: 1631524736.0000 - val_loss: 8500.0107 - val_mae: 8500.0107 - val_mse: 324739648.0000\n",
      "Epoch 99/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27905.1992 - mae: 27905.1992 - mse: 1855026304.0000 - val_loss: 38689.3398 - val_mae: 38689.3398 - val_mse: 1594838272.0000\n",
      "Epoch 100/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24080.6309 - mae: 24080.6309 - mse: 1588102144.0000 - val_loss: 12389.4346 - val_mae: 12389.4346 - val_mse: 415159872.0000\n",
      "Epoch 101/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27718.7988 - mae: 27718.7988 - mse: 1827997440.0000 - val_loss: 31311.3496 - val_mae: 31311.3496 - val_mse: 1041428800.0000\n",
      "Epoch 102/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23629.2500 - mae: 23629.2500 - mse: 1520478976.0000 - val_loss: 8439.7041 - val_mae: 8439.7041 - val_mse: 270671712.0000\n",
      "Epoch 103/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26620.9316 - mae: 26620.9316 - mse: 1717675648.0000 - val_loss: 22961.3887 - val_mae: 22961.3887 - val_mse: 784813120.0000\n",
      "Epoch 104/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23587.9863 - mae: 23587.9863 - mse: 1478945024.0000 - val_loss: 41247.4883 - val_mae: 41247.4883 - val_mse: 1814236416.0000\n",
      "Epoch 105/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23526.2285 - mae: 23526.2285 - mse: 1496801408.0000 - val_loss: 14453.2617 - val_mae: 14453.2617 - val_mse: 302169504.0000\n",
      "Epoch 106/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24545.2969 - mae: 24545.2969 - mse: 1613219712.0000 - val_loss: 28547.9473 - val_mae: 28547.9473 - val_mse: 867381312.0000\n",
      "Epoch 107/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 29255.1543 - mae: 29255.1543 - mse: 1943361792.0000 - val_loss: 51248.0273 - val_mae: 51248.0273 - val_mse: 2876958464.0000\n",
      "Epoch 108/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 36903.3789 - mae: 36903.3789 - mse: 2449125888.0000 - val_loss: 18916.0977 - val_mae: 18916.0977 - val_mse: 418412544.0000\n",
      "Epoch 109/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23219.6602 - mae: 23219.6602 - mse: 1509529856.0000 - val_loss: 11131.8096 - val_mae: 11131.8096 - val_mse: 258606656.0000\n",
      "Epoch 110/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21092.6641 - mae: 21092.6641 - mse: 1379848192.0000 - val_loss: 11918.5107 - val_mae: 11918.5107 - val_mse: 263836000.0000\n",
      "Epoch 111/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22457.7480 - mae: 22457.7480 - mse: 1384144512.0000 - val_loss: 8781.5918 - val_mae: 8781.5918 - val_mse: 255880368.0000\n",
      "Epoch 112/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25959.0605 - mae: 25959.0605 - mse: 1627832320.0000 - val_loss: 16723.0684 - val_mae: 16723.0684 - val_mse: 350925056.0000\n",
      "Epoch 113/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 28485.6055 - mae: 28485.6055 - mse: 1769472768.0000 - val_loss: 7906.0684 - val_mae: 7906.0684 - val_mse: 265323136.0000\n",
      "Epoch 114/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22962.1289 - mae: 22962.1289 - mse: 1484427648.0000 - val_loss: 38450.2539 - val_mae: 38450.2539 - val_mse: 1571185408.0000\n",
      "Epoch 115/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25943.0449 - mae: 25943.0449 - mse: 1611736448.0000 - val_loss: 27594.5430 - val_mae: 27594.5430 - val_mse: 810740736.0000\n",
      "Epoch 116/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23466.4375 - mae: 23466.4375 - mse: 1470811008.0000 - val_loss: 30146.7324 - val_mae: 30146.7324 - val_mse: 964164416.0000\n",
      "Epoch 117/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26678.5840 - mae: 26678.5840 - mse: 1653057920.0000 - val_loss: 32609.8887 - val_mae: 32609.8887 - val_mse: 1126534528.0000\n",
      "Epoch 118/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24124.4922 - mae: 24124.4922 - mse: 1524782848.0000 - val_loss: 33873.8672 - val_mae: 33873.8672 - val_mse: 1215393408.0000\n",
      "Epoch 119/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25871.2441 - mae: 25871.2441 - mse: 1547415552.0000 - val_loss: 7606.7275 - val_mae: 7606.7275 - val_mse: 268315840.0000\n",
      "Epoch 120/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21191.2500 - mae: 21191.2500 - mse: 1319569408.0000 - val_loss: 62279.4531 - val_mae: 62279.4531 - val_mse: 4111644416.0000\n",
      "Epoch 121/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24999.0391 - mae: 24999.0391 - mse: 1516098944.0000 - val_loss: 40727.8516 - val_mae: 40727.8516 - val_mse: 1763033600.0000\n",
      "Epoch 122/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 28931.0625 - mae: 28931.0625 - mse: 1785929728.0000 - val_loss: 45612.0703 - val_mae: 45612.0703 - val_mse: 2216777728.0000\n",
      "Epoch 123/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 28321.0352 - mae: 28321.0352 - mse: 1795001600.0000 - val_loss: 18486.0938 - val_mae: 18486.0938 - val_mse: 400603840.0000\n",
      "Epoch 124/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20337.2598 - mae: 20337.2598 - mse: 1260886784.0000 - val_loss: 9840.2773 - val_mae: 9840.2773 - val_mse: 241636176.0000\n",
      "Epoch 125/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20938.6914 - mae: 20938.6914 - mse: 1269964288.0000 - val_loss: 53094.8594 - val_mae: 53094.8594 - val_mse: 3003789568.0000\n",
      "Epoch 126/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21651.2637 - mae: 21651.2637 - mse: 1278181248.0000 - val_loss: 21681.3789 - val_mae: 21681.3789 - val_mse: 517081632.0000\n",
      "Epoch 127/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23628.9492 - mae: 23628.9492 - mse: 1412807040.0000 - val_loss: 33589.9492 - val_mae: 33589.9492 - val_mse: 1193491584.0000\n",
      "Epoch 128/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23203.9277 - mae: 23203.9277 - mse: 1383403136.0000 - val_loss: 28971.4141 - val_mae: 28971.4141 - val_mse: 1073704960.0000\n",
      "Epoch 129/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 28141.1777 - mae: 28141.1777 - mse: 1635024128.0000 - val_loss: 10860.8975 - val_mae: 10860.8975 - val_mse: 242296320.0000\n",
      "Epoch 130/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23793.9414 - mae: 23793.9414 - mse: 1391593600.0000 - val_loss: 20115.3828 - val_mae: 20115.3828 - val_mse: 454905600.0000\n",
      "Epoch 131/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22492.6504 - mae: 22492.6504 - mse: 1388833920.0000 - val_loss: 16475.0039 - val_mae: 16475.0039 - val_mse: 504692288.0000\n",
      "Epoch 132/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25749.4336 - mae: 25749.4336 - mse: 1509188096.0000 - val_loss: 32379.8633 - val_mae: 32379.8633 - val_mse: 1108162688.0000\n",
      "Epoch 133/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25197.3770 - mae: 25197.3770 - mse: 1621793280.0000 - val_loss: 34320.1406 - val_mae: 34320.1406 - val_mse: 1407879424.0000\n",
      "Epoch 134/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23732.2695 - mae: 23732.2695 - mse: 1374710528.0000 - val_loss: 9024.9629 - val_mae: 9024.9629 - val_mse: 233191744.0000\n",
      "Epoch 135/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20174.4707 - mae: 20174.4707 - mse: 1132141568.0000 - val_loss: 12726.3164 - val_mae: 12726.3164 - val_mse: 259360480.0000\n",
      "Epoch 136/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27943.8145 - mae: 27943.8145 - mse: 1637781120.0000 - val_loss: 20899.6445 - val_mae: 20899.6445 - val_mse: 483758432.0000\n",
      "Epoch 137/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24445.5508 - mae: 24445.5508 - mse: 1375955712.0000 - val_loss: 28021.1426 - val_mae: 28021.1426 - val_mse: 1013104064.0000\n",
      "Epoch 138/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23147.1133 - mae: 23147.1133 - mse: 1299339648.0000 - val_loss: 9378.6445 - val_mae: 9378.6445 - val_mse: 230195536.0000\n",
      "Epoch 139/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22333.5762 - mae: 22333.5762 - mse: 1322497152.0000 - val_loss: 43209.6680 - val_mae: 43209.6680 - val_mse: 1982983552.0000\n",
      "Epoch 140/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 20300.4824 - mae: 20300.4824 - mse: 1172830336.0000 - val_loss: 7252.6387 - val_mae: 7252.6387 - val_mse: 246238176.0000\n",
      "Epoch 141/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22339.8496 - mae: 22339.8496 - mse: 1235296128.0000 - val_loss: 25851.5039 - val_mae: 25851.5039 - val_mse: 711828160.0000\n",
      "Epoch 142/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21471.8203 - mae: 21471.8203 - mse: 1214453760.0000 - val_loss: 13082.6963 - val_mae: 13082.6963 - val_mse: 261924528.0000\n",
      "Epoch 143/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18974.2832 - mae: 18974.2832 - mse: 1127554688.0000 - val_loss: 37093.0234 - val_mae: 37093.0234 - val_mse: 1454652416.0000\n",
      "Epoch 144/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21209.9531 - mae: 21209.9531 - mse: 1216190848.0000 - val_loss: 7844.9722 - val_mae: 7844.9722 - val_mse: 229440512.0000\n",
      "Epoch 145/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20111.5879 - mae: 20111.5879 - mse: 1162258176.0000 - val_loss: 11049.4326 - val_mae: 11049.4326 - val_mse: 233976512.0000\n",
      "Epoch 146/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21486.7207 - mae: 21486.7207 - mse: 1177626880.0000 - val_loss: 13785.0371 - val_mae: 13785.0371 - val_mse: 411456544.0000\n",
      "Epoch 147/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21835.3359 - mae: 21835.3359 - mse: 1220281984.0000 - val_loss: 12109.1133 - val_mae: 12109.1133 - val_mse: 244912496.0000\n",
      "Epoch 148/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25298.7637 - mae: 25298.7637 - mse: 1385109376.0000 - val_loss: 29798.6953 - val_mae: 29798.6953 - val_mse: 937454400.0000\n",
      "Epoch 149/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20471.2676 - mae: 20471.2676 - mse: 1170167296.0000 - val_loss: 19818.1973 - val_mae: 19818.1973 - val_mse: 611499904.0000\n",
      "Epoch 150/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21642.8281 - mae: 21642.8281 - mse: 1188869376.0000 - val_loss: 12863.5322 - val_mae: 12863.5322 - val_mse: 254905664.0000\n",
      "Epoch 151/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21942.6523 - mae: 21942.6523 - mse: 1221009536.0000 - val_loss: 7548.0874 - val_mae: 7548.0874 - val_mse: 225253120.0000\n",
      "Epoch 152/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19815.7969 - mae: 19815.7969 - mse: 1090332160.0000 - val_loss: 23259.7988 - val_mae: 23259.7988 - val_mse: 582443584.0000\n",
      "Epoch 153/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19816.0762 - mae: 19816.0762 - mse: 1073598464.0000 - val_loss: 16402.1758 - val_mae: 16402.1758 - val_mse: 330571744.0000\n",
      "Epoch 154/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 23431.0410 - mae: 23431.0410 - mse: 1259737088.0000 - val_loss: 34492.3477 - val_mae: 34492.3477 - val_mse: 1254626560.0000\n",
      "Epoch 155/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21459.1562 - mae: 21459.1562 - mse: 1154744448.0000 - val_loss: 18916.8086 - val_mae: 18916.8086 - val_mse: 407030720.0000\n",
      "Epoch 156/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21811.8086 - mae: 21811.8086 - mse: 1190996480.0000 - val_loss: 27152.7441 - val_mae: 27152.7441 - val_mse: 780324480.0000\n",
      "Epoch 157/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21246.4102 - mae: 21246.4102 - mse: 1127360512.0000 - val_loss: 8476.4053 - val_mae: 8476.4053 - val_mse: 214994144.0000\n",
      "Epoch 158/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23350.2383 - mae: 23350.2383 - mse: 1252984064.0000 - val_loss: 50182.3477 - val_mae: 50182.3477 - val_mse: 2670628608.0000\n",
      "Epoch 159/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22755.0742 - mae: 22755.0742 - mse: 1244003072.0000 - val_loss: 59008.7734 - val_mae: 59008.7734 - val_mse: 3676594432.0000\n",
      "Epoch 160/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22371.3379 - mae: 22371.3379 - mse: 1193427968.0000 - val_loss: 38844.1914 - val_mae: 38844.1914 - val_mse: 1593367424.0000\n",
      "Epoch 161/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19347.0391 - mae: 19347.0391 - mse: 1014172864.0000 - val_loss: 7872.5127 - val_mae: 7872.5127 - val_mse: 214014240.0000\n",
      "Epoch 162/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20381.3164 - mae: 20381.3164 - mse: 1016051392.0000 - val_loss: 17702.5645 - val_mae: 17702.5645 - val_mse: 523109056.0000\n",
      "Epoch 163/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24553.9746 - mae: 24553.9746 - mse: 1308332928.0000 - val_loss: 13968.3506 - val_mae: 13968.3506 - val_mse: 270624704.0000\n",
      "Epoch 164/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22680.3301 - mae: 22680.3301 - mse: 1189552640.0000 - val_loss: 12644.3516 - val_mae: 12644.3516 - val_mse: 246415776.0000\n",
      "Epoch 165/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18688.5332 - mae: 18688.5332 - mse: 1000758144.0000 - val_loss: 35919.6797 - val_mae: 35919.6797 - val_mse: 1496496512.0000\n",
      "Epoch 166/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25967.5000 - mae: 25967.5000 - mse: 1350845952.0000 - val_loss: 6805.5000 - val_mae: 6805.5000 - val_mse: 236699040.0000\n",
      "Epoch 167/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24612.5781 - mae: 24612.5781 - mse: 1333165312.0000 - val_loss: 24889.5156 - val_mae: 24889.5156 - val_mse: 659003008.0000\n",
      "Epoch 168/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 17812.0566 - mae: 17812.0566 - mse: 964163648.0000 - val_loss: 8943.1367 - val_mae: 8943.1367 - val_mse: 286125312.0000\n",
      "Epoch 169/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21184.6133 - mae: 21184.6133 - mse: 1104091264.0000 - val_loss: 28438.3242 - val_mae: 28438.3242 - val_mse: 852448768.0000\n",
      "Epoch 170/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 22598.1172 - mae: 22598.1172 - mse: 1172768896.0000 - val_loss: 23732.9062 - val_mae: 23732.9062 - val_mse: 602423616.0000\n",
      "Epoch 171/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18181.7012 - mae: 18181.7012 - mse: 985606912.0000 - val_loss: 15821.0713 - val_mae: 15821.0713 - val_mse: 310735008.0000\n",
      "Epoch 172/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21635.8086 - mae: 21635.8086 - mse: 1132212480.0000 - val_loss: 28527.9883 - val_mae: 28527.9883 - val_mse: 857269568.0000\n",
      "Epoch 173/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23486.3730 - mae: 23486.3730 - mse: 1215074560.0000 - val_loss: 25451.7734 - val_mae: 25451.7734 - val_mse: 687022080.0000\n",
      "Epoch 174/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20454.6406 - mae: 20454.6406 - mse: 1008393984.0000 - val_loss: 6691.7212 - val_mae: 6691.7212 - val_mse: 218985840.0000\n",
      "Epoch 175/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19776.7363 - mae: 19776.7363 - mse: 1034619456.0000 - val_loss: 15632.8877 - val_mae: 15632.8877 - val_mse: 446552032.0000\n",
      "Epoch 176/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19183.6465 - mae: 19183.6465 - mse: 989499584.0000 - val_loss: 17418.3457 - val_mae: 17418.3457 - val_mse: 354808608.0000\n",
      "Epoch 177/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20349.9238 - mae: 20349.9238 - mse: 1009589376.0000 - val_loss: 14378.6826 - val_mae: 14378.6826 - val_mse: 275213440.0000\n",
      "Epoch 178/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18153.1816 - mae: 18153.1816 - mse: 929501632.0000 - val_loss: 14943.1484 - val_mae: 14943.1484 - val_mse: 287551616.0000\n",
      "Epoch 179/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19839.6641 - mae: 19839.6641 - mse: 1049768640.0000 - val_loss: 6914.6685 - val_mae: 6914.6685 - val_mse: 208334064.0000\n",
      "Epoch 180/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18169.9805 - mae: 18169.9805 - mse: 935032064.0000 - val_loss: 21906.5234 - val_mae: 21906.5234 - val_mse: 678328832.0000\n",
      "Epoch 181/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19075.0352 - mae: 19075.0352 - mse: 940843776.0000 - val_loss: 6833.6338 - val_mae: 6833.6338 - val_mse: 237710816.0000\n",
      "Epoch 182/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24263.0488 - mae: 24263.0488 - mse: 1242472064.0000 - val_loss: 7652.3677 - val_mae: 7652.3677 - val_mse: 254678224.0000\n",
      "Epoch 183/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22998.5547 - mae: 22998.5547 - mse: 1204698240.0000 - val_loss: 18396.4316 - val_mae: 18396.4316 - val_mse: 384825312.0000\n",
      "Epoch 184/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16781.5820 - mae: 16781.5820 - mse: 875611968.0000 - val_loss: 8999.9580 - val_mae: 8999.9580 - val_mse: 199966080.0000\n",
      "Epoch 185/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17279.7461 - mae: 17279.7461 - mse: 853201408.0000 - val_loss: 13018.3506 - val_mae: 13018.3506 - val_mse: 245960352.0000\n",
      "Epoch 186/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17124.4590 - mae: 17124.4590 - mse: 897561344.0000 - val_loss: 27850.3613 - val_mae: 27850.3613 - val_mse: 816058432.0000\n",
      "Epoch 187/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20616.5723 - mae: 20616.5723 - mse: 1080235136.0000 - val_loss: 31382.3555 - val_mae: 31382.3555 - val_mse: 1034101632.0000\n",
      "Epoch 188/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19171.0801 - mae: 19171.0801 - mse: 1014012288.0000 - val_loss: 23262.6152 - val_mae: 23262.6152 - val_mse: 578280064.0000\n",
      "Epoch 189/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22226.2188 - mae: 22226.2188 - mse: 1095484288.0000 - val_loss: 54791.4688 - val_mae: 54791.4688 - val_mse: 3166193664.0000\n",
      "Epoch 190/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23057.6270 - mae: 23057.6270 - mse: 1195271296.0000 - val_loss: 8858.5889 - val_mae: 8858.5889 - val_mse: 196197696.0000\n",
      "Epoch 191/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20059.6855 - mae: 20059.6855 - mse: 1019761728.0000 - val_loss: 16339.9922 - val_mae: 16339.9922 - val_mse: 320414176.0000\n",
      "Epoch 192/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19475.6836 - mae: 19475.6836 - mse: 997758784.0000 - val_loss: 22916.1621 - val_mae: 22916.1621 - val_mse: 716473152.0000\n",
      "Epoch 193/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19186.2207 - mae: 19186.2207 - mse: 968207808.0000 - val_loss: 20076.5723 - val_mae: 20076.5723 - val_mse: 443431232.0000\n",
      "Epoch 194/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17343.5156 - mae: 17343.5156 - mse: 872214272.0000 - val_loss: 13725.5156 - val_mae: 13725.5156 - val_mse: 256810784.0000\n",
      "Epoch 195/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16891.1953 - mae: 16891.1953 - mse: 884506176.0000 - val_loss: 15645.5264 - val_mae: 15645.5264 - val_mse: 434801248.0000\n",
      "Epoch 196/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19495.1035 - mae: 19495.1035 - mse: 950578560.0000 - val_loss: 20637.6191 - val_mae: 20637.6191 - val_mse: 464660096.0000\n",
      "Epoch 197/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20545.2383 - mae: 20545.2383 - mse: 1056707392.0000 - val_loss: 57978.4492 - val_mae: 57978.4492 - val_mse: 3531831296.0000\n",
      "Epoch 198/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20555.9766 - mae: 20555.9766 - mse: 986920576.0000 - val_loss: 45866.2812 - val_mae: 45866.2812 - val_mse: 2219005184.0000\n",
      "Epoch 199/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18185.5195 - mae: 18185.5195 - mse: 922213696.0000 - val_loss: 20196.2344 - val_mae: 20196.2344 - val_mse: 447199712.0000\n",
      "Epoch 200/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21561.8379 - mae: 21561.8379 - mse: 1047716352.0000 - val_loss: 11175.8369 - val_mae: 11175.8369 - val_mse: 212940672.0000\n",
      "Epoch 201/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18525.9844 - mae: 18525.9844 - mse: 916225280.0000 - val_loss: 6498.1216 - val_mae: 6498.1216 - val_mse: 196015440.0000\n",
      "Epoch 202/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16479.9453 - mae: 16479.9453 - mse: 853805952.0000 - val_loss: 23135.8906 - val_mae: 23135.8906 - val_mse: 571065088.0000\n",
      "Epoch 203/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16972.5000 - mae: 16972.5000 - mse: 844656448.0000 - val_loss: 31139.6191 - val_mae: 31139.6191 - val_mse: 1154241280.0000\n",
      "Epoch 204/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25429.9180 - mae: 25429.9180 - mse: 1339213568.0000 - val_loss: 12424.1963 - val_mae: 12424.1963 - val_mse: 230054176.0000\n",
      "Epoch 205/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22995.7324 - mae: 22995.7324 - mse: 1087212288.0000 - val_loss: 16054.5322 - val_mae: 16054.5322 - val_mse: 310174976.0000\n",
      "Epoch 206/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20881.1016 - mae: 20881.1016 - mse: 1005619840.0000 - val_loss: 12889.3457 - val_mae: 12889.3457 - val_mse: 237866096.0000\n",
      "Epoch 207/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21440.0254 - mae: 21440.0254 - mse: 1038261568.0000 - val_loss: 46148.0859 - val_mae: 46148.0859 - val_mse: 2244805120.0000\n",
      "Epoch 208/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19198.9824 - mae: 19198.9824 - mse: 938310336.0000 - val_loss: 27255.4180 - val_mae: 27255.4180 - val_mse: 780744192.0000\n",
      "Epoch 209/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20769.9902 - mae: 20769.9902 - mse: 1016919040.0000 - val_loss: 8984.0400 - val_mae: 8984.0400 - val_mse: 189035136.0000\n",
      "Epoch 210/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23497.3945 - mae: 23497.3945 - mse: 1204220032.0000 - val_loss: 6864.1636 - val_mae: 6864.1636 - val_mse: 226515232.0000\n",
      "Epoch 211/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 16131.0137 - mae: 16131.0137 - mse: 806152384.0000 - val_loss: 11730.2695 - val_mae: 11730.2695 - val_mse: 320331584.0000\n",
      "Epoch 212/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16295.2871 - mae: 16295.2871 - mse: 821374272.0000 - val_loss: 26643.1836 - val_mae: 26643.1836 - val_mse: 746513472.0000\n",
      "Epoch 213/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17409.9570 - mae: 17409.9570 - mse: 893441472.0000 - val_loss: 7511.9800 - val_mae: 7511.9800 - val_mse: 183255152.0000\n",
      "Epoch 214/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26375.9004 - mae: 26375.9004 - mse: 1391720832.0000 - val_loss: 75037.0625 - val_mae: 75037.0625 - val_mse: 5820595200.0000\n",
      "Epoch 215/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23926.7266 - mae: 23926.7266 - mse: 1178959616.0000 - val_loss: 26642.8223 - val_mae: 26642.8223 - val_mse: 746416960.0000\n",
      "Epoch 216/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18610.7695 - mae: 18610.7695 - mse: 906043072.0000 - val_loss: 7838.0391 - val_mae: 7838.0391 - val_mse: 239723152.0000\n",
      "Epoch 217/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19896.9258 - mae: 19896.9258 - mse: 968495744.0000 - val_loss: 13441.0254 - val_mae: 13441.0254 - val_mse: 361412960.0000\n",
      "Epoch 218/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18461.2559 - mae: 18461.2559 - mse: 906274240.0000 - val_loss: 11918.4873 - val_mae: 11918.4873 - val_mse: 218928448.0000\n",
      "Epoch 219/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21163.6660 - mae: 21163.6660 - mse: 1006467648.0000 - val_loss: 39079.3828 - val_mae: 39079.3828 - val_mse: 1603718144.0000\n",
      "Epoch 220/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16284.6924 - mae: 16284.6924 - mse: 822703360.0000 - val_loss: 6253.1758 - val_mae: 6253.1758 - val_mse: 209348928.0000\n",
      "Epoch 221/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18805.1191 - mae: 18805.1191 - mse: 960193920.0000 - val_loss: 15782.8242 - val_mae: 15782.8242 - val_mse: 300700896.0000\n",
      "Epoch 222/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20374.5449 - mae: 20374.5449 - mse: 982618688.0000 - val_loss: 8270.3535 - val_mae: 8270.3535 - val_mse: 181161904.0000\n",
      "Epoch 223/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17464.1660 - mae: 17464.1660 - mse: 905644992.0000 - val_loss: 6104.8926 - val_mae: 6104.8926 - val_mse: 188215712.0000\n",
      "Epoch 224/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16396.3730 - mae: 16396.3730 - mse: 860580736.0000 - val_loss: 8413.9678 - val_mae: 8413.9678 - val_mse: 180798576.0000\n",
      "Epoch 225/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25435.9863 - mae: 25435.9863 - mse: 1279982848.0000 - val_loss: 13064.7197 - val_mae: 13064.7197 - val_mse: 347743008.0000\n",
      "Epoch 226/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17497.1406 - mae: 17497.1406 - mse: 858251264.0000 - val_loss: 38835.9258 - val_mae: 38835.9258 - val_mse: 1582753408.0000\n",
      "Epoch 227/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17585.9141 - mae: 17585.9141 - mse: 857728576.0000 - val_loss: 24655.6875 - val_mae: 24655.6875 - val_mse: 783294080.0000\n",
      "Epoch 228/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16142.9414 - mae: 16142.9414 - mse: 820995712.0000 - val_loss: 8854.2822 - val_mae: 8854.2822 - val_mse: 181880016.0000\n",
      "Epoch 229/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16131.7930 - mae: 16131.7930 - mse: 785839680.0000 - val_loss: 10098.5635 - val_mae: 10098.5635 - val_mse: 192051856.0000\n",
      "Epoch 230/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19606.9023 - mae: 19606.9023 - mse: 961820032.0000 - val_loss: 25856.6172 - val_mae: 25856.6172 - val_mse: 703367552.0000\n",
      "Epoch 231/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19580.4863 - mae: 19580.4863 - mse: 952243968.0000 - val_loss: 26926.7129 - val_mae: 26926.7129 - val_mse: 761261952.0000\n",
      "Epoch 232/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19893.4453 - mae: 19893.4453 - mse: 933063552.0000 - val_loss: 16429.5430 - val_mae: 16429.5430 - val_mse: 317338688.0000\n",
      "Epoch 233/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17270.0625 - mae: 17270.0625 - mse: 809634880.0000 - val_loss: 18454.3223 - val_mae: 18454.3223 - val_mse: 380824704.0000\n",
      "Epoch 234/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17550.5098 - mae: 17550.5098 - mse: 819137856.0000 - val_loss: 21993.5410 - val_mae: 21993.5410 - val_mse: 517481280.0000\n",
      "Epoch 235/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19594.8887 - mae: 19594.8887 - mse: 917543872.0000 - val_loss: 14035.9580 - val_mae: 14035.9580 - val_mse: 255810224.0000\n",
      "Epoch 236/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19102.6758 - mae: 19102.6758 - mse: 972168960.0000 - val_loss: 30676.9727 - val_mae: 30676.9727 - val_mse: 984634816.0000\n",
      "Epoch 237/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17927.3887 - mae: 17927.3887 - mse: 914999168.0000 - val_loss: 12800.9580 - val_mae: 12800.9580 - val_mse: 230096384.0000\n",
      "Epoch 238/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18657.5371 - mae: 18657.5371 - mse: 978491264.0000 - val_loss: 6410.9873 - val_mae: 6410.9873 - val_mse: 206561280.0000\n",
      "Epoch 239/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18289.0625 - mae: 18289.0625 - mse: 939178176.0000 - val_loss: 23560.7188 - val_mae: 23560.7188 - val_mse: 725537408.0000\n",
      "Epoch 240/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 18360.6484 - mae: 18360.6484 - mse: 937729536.0000 - val_loss: 10319.8955 - val_mae: 10319.8955 - val_mse: 275285792.0000\n",
      "Epoch 241/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20382.3164 - mae: 20382.3164 - mse: 974840064.0000 - val_loss: 9062.1416 - val_mae: 9062.1416 - val_mse: 179028128.0000\n",
      "Epoch 242/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16853.9629 - mae: 16853.9629 - mse: 895251776.0000 - val_loss: 24073.3613 - val_mae: 24073.3613 - val_mse: 612603520.0000\n",
      "Epoch 243/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20296.8711 - mae: 20296.8711 - mse: 968551936.0000 - val_loss: 11946.2930 - val_mae: 11946.2930 - val_mse: 213730768.0000\n",
      "Epoch 244/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17282.4785 - mae: 17282.4785 - mse: 861126464.0000 - val_loss: 5774.9766 - val_mae: 5774.9766 - val_mse: 180086016.0000\n",
      "Epoch 245/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20057.7676 - mae: 20057.7676 - mse: 1044310976.0000 - val_loss: 34853.7148 - val_mae: 34853.7148 - val_mse: 1381653120.0000\n",
      "Epoch 246/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19472.5332 - mae: 19472.5332 - mse: 936768128.0000 - val_loss: 30253.4414 - val_mae: 30253.4414 - val_mse: 957104064.0000\n",
      "Epoch 247/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19843.6875 - mae: 19843.6875 - mse: 960399040.0000 - val_loss: 13962.4453 - val_mae: 13962.4453 - val_mse: 252336464.0000\n",
      "Epoch 248/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18681.5254 - mae: 18681.5254 - mse: 892977408.0000 - val_loss: 15817.9941 - val_mae: 15817.9941 - val_mse: 298306816.0000\n",
      "Epoch 249/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 18476.8496 - mae: 18476.8496 - mse: 902231040.0000 - val_loss: 45339.9883 - val_mae: 45339.9883 - val_mse: 2159017728.0000\n",
      "Epoch 250/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 30087.2500 - mae: 30087.2500 - mse: 1552985856.0000 - val_loss: 18129.9492 - val_mae: 18129.9492 - val_mse: 495130656.0000\n",
      "Epoch 251/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16587.3125 - mae: 16587.3125 - mse: 834060352.0000 - val_loss: 15398.4736 - val_mae: 15398.4736 - val_mse: 286814304.0000\n",
      "Epoch 252/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 21416.2012 - mae: 21416.2012 - mse: 1015591680.0000 - val_loss: 8135.8677 - val_mae: 8135.8677 - val_mse: 227038160.0000\n",
      "Epoch 253/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24428.2539 - mae: 24428.2539 - mse: 1184852096.0000 - val_loss: 26169.2832 - val_mae: 26169.2832 - val_mse: 719189888.0000\n",
      "Epoch 254/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14701.4688 - mae: 14701.4688 - mse: 724566464.0000 - val_loss: 13134.0391 - val_mae: 13134.0391 - val_mse: 233877616.0000\n",
      "Epoch 255/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22242.6270 - mae: 22242.6270 - mse: 1051228608.0000 - val_loss: 38297.8438 - val_mae: 38297.8438 - val_mse: 1535853440.0000\n",
      "Epoch 256/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19222.7598 - mae: 19222.7598 - mse: 883232128.0000 - val_loss: 8818.7090 - val_mae: 8818.7090 - val_mse: 237848288.0000\n",
      "Epoch 257/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22772.3965 - mae: 22772.3965 - mse: 1102302592.0000 - val_loss: 23330.6934 - val_mae: 23330.6934 - val_mse: 708184768.0000\n",
      "Epoch 258/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18034.1016 - mae: 18034.1016 - mse: 860168256.0000 - val_loss: 13367.5859 - val_mae: 13367.5859 - val_mse: 238230272.0000\n",
      "Epoch 259/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18128.8574 - mae: 18128.8574 - mse: 870409664.0000 - val_loss: 9072.5684 - val_mae: 9072.5684 - val_mse: 241598928.0000\n",
      "Epoch 260/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14900.8789 - mae: 14900.8789 - mse: 747885312.0000 - val_loss: 9802.9893 - val_mae: 9802.9893 - val_mse: 181241856.0000\n",
      "Epoch 261/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17214.8828 - mae: 17214.8828 - mse: 807340672.0000 - val_loss: 15548.3066 - val_mae: 15548.3066 - val_mse: 289833824.0000\n",
      "Epoch 262/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14360.4727 - mae: 14360.4727 - mse: 710255168.0000 - val_loss: 5617.5854 - val_mae: 5617.5854 - val_mse: 172288736.0000\n",
      "Epoch 263/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16963.5352 - mae: 16963.5352 - mse: 793899776.0000 - val_loss: 14264.1309 - val_mae: 14264.1309 - val_mse: 257508688.0000\n",
      "Epoch 264/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 20135.5918 - mae: 20135.5918 - mse: 903604288.0000 - val_loss: 32945.6641 - val_mae: 32945.6641 - val_mse: 1133844608.0000\n",
      "Epoch 265/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19546.3008 - mae: 19546.3008 - mse: 858298176.0000 - val_loss: 6682.0278 - val_mae: 6682.0278 - val_mse: 199035056.0000\n",
      "Epoch 266/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15078.2529 - mae: 15078.2529 - mse: 709852224.0000 - val_loss: 18165.1426 - val_mae: 18165.1426 - val_mse: 368580896.0000\n",
      "Epoch 267/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17979.6719 - mae: 17979.6719 - mse: 848049088.0000 - val_loss: 26779.9844 - val_mae: 26779.9844 - val_mse: 877444672.0000\n",
      "Epoch 268/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20043.6328 - mae: 20043.6328 - mse: 909429568.0000 - val_loss: 8128.7354 - val_mae: 8128.7354 - val_mse: 220770160.0000\n",
      "Epoch 269/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16987.4688 - mae: 16987.4688 - mse: 793394752.0000 - val_loss: 15873.2383 - val_mae: 15873.2383 - val_mse: 298075392.0000\n",
      "Epoch 270/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14563.3857 - mae: 14563.3857 - mse: 705907008.0000 - val_loss: 8239.0889 - val_mae: 8239.0889 - val_mse: 221808320.0000\n",
      "Epoch 271/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19581.4668 - mae: 19581.4668 - mse: 869838784.0000 - val_loss: 19603.9414 - val_mae: 19603.9414 - val_mse: 543987264.0000\n",
      "Epoch 272/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18564.1309 - mae: 18564.1309 - mse: 852106112.0000 - val_loss: 6331.5015 - val_mae: 6331.5015 - val_mse: 161595872.0000\n",
      "Epoch 273/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18746.8242 - mae: 18746.8242 - mse: 842163328.0000 - val_loss: 5623.1855 - val_mae: 5623.1855 - val_mse: 166398208.0000\n",
      "Epoch 274/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15424.2803 - mae: 15424.2803 - mse: 702606720.0000 - val_loss: 11030.9746 - val_mae: 11030.9746 - val_mse: 277711488.0000\n",
      "Epoch 275/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15751.4648 - mae: 15751.4648 - mse: 738029568.0000 - val_loss: 21483.6602 - val_mae: 21483.6602 - val_mse: 494185792.0000\n",
      "Epoch 276/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19848.7520 - mae: 19848.7520 - mse: 877716288.0000 - val_loss: 6987.9829 - val_mae: 6987.9829 - val_mse: 199728320.0000\n",
      "Epoch 277/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19201.8496 - mae: 19201.8496 - mse: 860935808.0000 - val_loss: 28699.3887 - val_mae: 28699.3887 - val_mse: 861732352.0000\n",
      "Epoch 278/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17382.2598 - mae: 17382.2598 - mse: 812785856.0000 - val_loss: 19973.5039 - val_mae: 19973.5039 - val_mse: 433276512.0000\n",
      "Epoch 279/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15050.9531 - mae: 15050.9531 - mse: 708770944.0000 - val_loss: 7622.9688 - val_mae: 7622.9688 - val_mse: 160861616.0000\n",
      "Epoch 280/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21676.6172 - mae: 21676.6172 - mse: 999017152.0000 - val_loss: 32984.3906 - val_mae: 32984.3906 - val_mse: 1136443008.0000\n",
      "Epoch 281/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19200.2559 - mae: 19200.2559 - mse: 881222720.0000 - val_loss: 13612.6182 - val_mae: 13612.6182 - val_mse: 241088960.0000\n",
      "Epoch 282/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15665.0635 - mae: 15665.0635 - mse: 748301504.0000 - val_loss: 11402.1699 - val_mae: 11402.1699 - val_mse: 199190096.0000\n",
      "Epoch 283/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14845.7988 - mae: 14845.7988 - mse: 688085888.0000 - val_loss: 19841.6406 - val_mae: 19841.6406 - val_mse: 428122336.0000\n",
      "Epoch 284/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15332.9150 - mae: 15332.9150 - mse: 709464256.0000 - val_loss: 13757.7598 - val_mae: 13757.7598 - val_mse: 344337184.0000\n",
      "Epoch 285/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15257.9355 - mae: 15257.9355 - mse: 674582720.0000 - val_loss: 14473.0938 - val_mae: 14473.0938 - val_mse: 260614208.0000\n",
      "Epoch 286/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16762.1289 - mae: 16762.1289 - mse: 761763904.0000 - val_loss: 23700.1777 - val_mae: 23700.1777 - val_mse: 594442752.0000\n",
      "Epoch 287/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23348.0098 - mae: 23348.0098 - mse: 1088049024.0000 - val_loss: 14874.1943 - val_mae: 14874.1943 - val_mse: 376153760.0000\n",
      "Epoch 288/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 17476.1777 - mae: 17476.1777 - mse: 806617856.0000 - val_loss: 10859.0156 - val_mae: 10859.0156 - val_mse: 190165264.0000\n",
      "Epoch 289/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22442.6914 - mae: 22442.6914 - mse: 1032618112.0000 - val_loss: 31345.0410 - val_mae: 31345.0410 - val_mse: 1136674432.0000\n",
      "Epoch 290/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18447.0195 - mae: 18447.0195 - mse: 849185920.0000 - val_loss: 25453.0137 - val_mae: 25453.0137 - val_mse: 802208576.0000\n",
      "Epoch 291/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26859.7285 - mae: 26859.7285 - mse: 1226735104.0000 - val_loss: 15230.5371 - val_mae: 15230.5371 - val_mse: 386313408.0000\n",
      "Epoch 292/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18396.1523 - mae: 18396.1523 - mse: 809563328.0000 - val_loss: 35987.1914 - val_mae: 35987.1914 - val_mse: 1353252480.0000\n",
      "Epoch 293/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20562.9375 - mae: 20562.9375 - mse: 941654336.0000 - val_loss: 25419.1953 - val_mae: 25419.1953 - val_mse: 679552128.0000\n",
      "Epoch 294/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15888.9590 - mae: 15888.9590 - mse: 719419200.0000 - val_loss: 13942.4023 - val_mae: 13942.4023 - val_mse: 247563616.0000\n",
      "Epoch 295/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17196.0547 - mae: 17196.0547 - mse: 789480960.0000 - val_loss: 15644.6562 - val_mae: 15644.6562 - val_mse: 290367968.0000\n",
      "Epoch 296/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18838.3203 - mae: 18838.3203 - mse: 804273152.0000 - val_loss: 20186.1582 - val_mae: 20186.1582 - val_mse: 441270272.0000\n",
      "Epoch 297/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19944.1719 - mae: 19944.1719 - mse: 937940480.0000 - val_loss: 43770.2461 - val_mae: 43770.2461 - val_mse: 2067857408.0000\n",
      "Epoch 298/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25014.1035 - mae: 25014.1035 - mse: 1163838464.0000 - val_loss: 52667.7266 - val_mae: 52667.7266 - val_mse: 2899738624.0000\n",
      "Epoch 299/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20280.5156 - mae: 20280.5156 - mse: 899842048.0000 - val_loss: 16212.6836 - val_mae: 16212.6836 - val_mse: 416194624.0000\n",
      "Epoch 300/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14037.7295 - mae: 14037.7295 - mse: 639346688.0000 - val_loss: 34809.9688 - val_mae: 34809.9688 - val_mse: 1265625984.0000\n",
      "Epoch 301/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25803.0625 - mae: 25803.0625 - mse: 1152587136.0000 - val_loss: 23895.6953 - val_mae: 23895.6953 - val_mse: 603839680.0000\n",
      "Epoch 302/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18474.5156 - mae: 18474.5156 - mse: 793290752.0000 - val_loss: 6514.9067 - val_mae: 6514.9067 - val_mse: 185628272.0000\n",
      "Epoch 303/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16150.5703 - mae: 16150.5703 - mse: 740052608.0000 - val_loss: 5727.5825 - val_mae: 5727.5825 - val_mse: 156318016.0000\n",
      "Epoch 304/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15077.1533 - mae: 15077.1533 - mse: 691643456.0000 - val_loss: 18410.1895 - val_mae: 18410.1895 - val_mse: 375815776.0000\n",
      "Epoch 305/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20728.4141 - mae: 20728.4141 - mse: 950047808.0000 - val_loss: 59912.1250 - val_mae: 59912.1250 - val_mse: 3728140544.0000\n",
      "Epoch 306/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24112.6602 - mae: 24112.6602 - mse: 1069698432.0000 - val_loss: 18533.4062 - val_mae: 18533.4062 - val_mse: 495598400.0000\n",
      "Epoch 307/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16457.2969 - mae: 16457.2969 - mse: 714107712.0000 - val_loss: 29336.6113 - val_mae: 29336.6113 - val_mse: 899730048.0000\n",
      "Epoch 308/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22425.4492 - mae: 22425.4492 - mse: 972315904.0000 - val_loss: 29401.6953 - val_mae: 29401.6953 - val_mse: 1015567808.0000\n",
      "Epoch 309/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 21004.5703 - mae: 21004.5703 - mse: 940363264.0000 - val_loss: 5309.4893 - val_mae: 5309.4893 - val_mse: 162184064.0000\n",
      "Epoch 310/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19599.0195 - mae: 19599.0195 - mse: 907953280.0000 - val_loss: 24964.2285 - val_mae: 24964.2285 - val_mse: 656294272.0000\n",
      "Epoch 311/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15915.1611 - mae: 15915.1611 - mse: 676993536.0000 - val_loss: 17755.6504 - val_mae: 17755.6504 - val_mse: 353624096.0000\n",
      "Epoch 312/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18271.4414 - mae: 18271.4414 - mse: 787360512.0000 - val_loss: 46500.5977 - val_mae: 46500.5977 - val_mse: 2311836416.0000\n",
      "Epoch 313/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17900.9980 - mae: 17900.9980 - mse: 769571072.0000 - val_loss: 16960.5879 - val_mae: 16960.5879 - val_mse: 328210912.0000\n",
      "Epoch 314/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18108.5664 - mae: 18108.5664 - mse: 796778176.0000 - val_loss: 6332.9175 - val_mae: 6332.9175 - val_mse: 180872320.0000\n",
      "Epoch 315/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19046.2793 - mae: 19046.2793 - mse: 825833984.0000 - val_loss: 13564.9766 - val_mae: 13564.9766 - val_mse: 333217376.0000\n",
      "Epoch 316/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15266.6240 - mae: 15266.6240 - mse: 695577920.0000 - val_loss: 17649.0000 - val_mae: 17649.0000 - val_mse: 462131200.0000\n",
      "Epoch 317/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21373.3652 - mae: 21373.3652 - mse: 939738560.0000 - val_loss: 7533.7852 - val_mae: 7533.7852 - val_mse: 154412704.0000\n",
      "Epoch 318/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15918.6182 - mae: 15918.6182 - mse: 721362560.0000 - val_loss: 20129.0391 - val_mae: 20129.0391 - val_mse: 439016160.0000\n",
      "Epoch 319/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24323.2969 - mae: 24323.2969 - mse: 1100621440.0000 - val_loss: 14989.7461 - val_mae: 14989.7461 - val_mse: 271977728.0000\n",
      "Epoch 320/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 20070.0312 - mae: 20070.0312 - mse: 924109440.0000 - val_loss: 27286.1719 - val_mae: 27286.1719 - val_mse: 779926848.0000\n",
      "Epoch 321/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14576.5264 - mae: 14576.5264 - mse: 656331200.0000 - val_loss: 10160.1514 - val_mae: 10160.1514 - val_mse: 177700656.0000\n",
      "Epoch 322/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 12754.7852 - mae: 12754.7852 - mse: 595278656.0000 - val_loss: 6838.7212 - val_mae: 6838.7212 - val_mse: 186359600.0000\n",
      "Epoch 323/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25953.5332 - mae: 25953.5332 - mse: 1284856960.0000 - val_loss: 13704.7852 - val_mae: 13704.7852 - val_mse: 240656080.0000\n",
      "Epoch 324/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17509.8652 - mae: 17509.8652 - mse: 736946240.0000 - val_loss: 17241.9414 - val_mae: 17241.9414 - val_mse: 336760416.0000\n",
      "Epoch 325/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14850.7275 - mae: 14850.7275 - mse: 668914624.0000 - val_loss: 6057.7397 - val_mae: 6057.7397 - val_mse: 174991504.0000\n",
      "Epoch 326/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15255.0283 - mae: 15255.0283 - mse: 674015744.0000 - val_loss: 21934.6348 - val_mae: 21934.6348 - val_mse: 629851200.0000\n",
      "Epoch 327/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18014.9844 - mae: 18014.9844 - mse: 745153344.0000 - val_loss: 25704.5664 - val_mae: 25704.5664 - val_mse: 694400448.0000\n",
      "Epoch 328/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 16746.7773 - mae: 16746.7773 - mse: 698429888.0000 - val_loss: 9568.4365 - val_mae: 9568.4365 - val_mse: 169774336.0000\n",
      "Epoch 329/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16644.9453 - mae: 16644.9453 - mse: 713841088.0000 - val_loss: 12895.3271 - val_mae: 12895.3271 - val_mse: 222855904.0000\n",
      "Epoch 330/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15385.5635 - mae: 15385.5635 - mse: 668535488.0000 - val_loss: 11847.2461 - val_mae: 11847.2461 - val_mse: 284696352.0000\n",
      "Epoch 331/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 33245.6719 - mae: 33245.6719 - mse: 1743274624.0000 - val_loss: 42582.0078 - val_mae: 42582.0078 - val_mse: 1960085376.0000\n",
      "Epoch 332/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15178.3145 - mae: 15178.3145 - mse: 709175232.0000 - val_loss: 22640.6953 - val_mae: 22640.6953 - val_mse: 545227392.0000\n",
      "Epoch 333/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20299.2734 - mae: 20299.2734 - mse: 877322304.0000 - val_loss: 15513.0391 - val_mae: 15513.0391 - val_mse: 285428128.0000\n",
      "Epoch 334/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17500.6660 - mae: 17500.6660 - mse: 753256320.0000 - val_loss: 11033.5439 - val_mae: 11033.5439 - val_mse: 189086816.0000\n",
      "Epoch 335/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16370.1406 - mae: 16370.1406 - mse: 677250112.0000 - val_loss: 31181.3574 - val_mae: 31181.3574 - val_mse: 1015891840.0000\n",
      "Epoch 336/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14175.7061 - mae: 14175.7061 - mse: 616734272.0000 - val_loss: 14837.8799 - val_mae: 14837.8799 - val_mse: 267434832.0000\n",
      "Epoch 337/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19833.0508 - mae: 19833.0508 - mse: 849418624.0000 - val_loss: 9954.5439 - val_mae: 9954.5439 - val_mse: 173691584.0000\n",
      "Epoch 338/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15232.1719 - mae: 15232.1719 - mse: 665984832.0000 - val_loss: 11476.5156 - val_mae: 11476.5156 - val_mse: 195950784.0000\n",
      "Epoch 339/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13190.8555 - mae: 13190.8555 - mse: 599143168.0000 - val_loss: 13439.1650 - val_mae: 13439.1650 - val_mse: 233979936.0000\n",
      "Epoch 340/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17598.2344 - mae: 17598.2344 - mse: 761718272.0000 - val_loss: 9772.9502 - val_mae: 9772.9502 - val_mse: 171119808.0000\n",
      "Epoch 341/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 15282.8613 - mae: 15282.8613 - mse: 655364096.0000 - val_loss: 22175.1074 - val_mae: 22175.1074 - val_mse: 524479808.0000\n",
      "Epoch 342/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16534.1387 - mae: 16534.1387 - mse: 705811520.0000 - val_loss: 5898.7588 - val_mae: 5898.7588 - val_mse: 148350528.0000\n",
      "Epoch 343/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13846.3418 - mae: 13846.3418 - mse: 613105408.0000 - val_loss: 9782.9609 - val_mae: 9782.9609 - val_mse: 234504832.0000\n",
      "Epoch 344/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19440.5918 - mae: 19440.5918 - mse: 893894912.0000 - val_loss: 50615.5391 - val_mae: 50615.5391 - val_mse: 2706309888.0000\n",
      "Epoch 345/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18711.4824 - mae: 18711.4824 - mse: 810890240.0000 - val_loss: 17303.7598 - val_mae: 17303.7598 - val_mse: 445518176.0000\n",
      "Epoch 346/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16532.4805 - mae: 16532.4805 - mse: 691909120.0000 - val_loss: 21528.8574 - val_mae: 21528.8574 - val_mse: 496443328.0000\n",
      "Epoch 347/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19211.4902 - mae: 19211.4902 - mse: 840726976.0000 - val_loss: 20512.1230 - val_mae: 20512.1230 - val_mse: 454422784.0000\n",
      "Epoch 348/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18598.6191 - mae: 18598.6191 - mse: 739476736.0000 - val_loss: 16333.4248 - val_mae: 16333.4248 - val_mse: 308347136.0000\n",
      "Epoch 349/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24467.9336 - mae: 24467.9336 - mse: 1152960256.0000 - val_loss: 88932.1094 - val_mae: 88932.1094 - val_mse: 8064963072.0000\n",
      "Epoch 350/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 33341.4570 - mae: 33341.4570 - mse: 1795300736.0000 - val_loss: 13176.8926 - val_mae: 13176.8926 - val_mse: 227747376.0000\n",
      "Epoch 351/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 18654.6992 - mae: 18654.6992 - mse: 879205504.0000 - val_loss: 21663.9551 - val_mae: 21663.9551 - val_mse: 502121664.0000\n",
      "Epoch 352/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26308.1367 - mae: 26308.1367 - mse: 1251005056.0000 - val_loss: 21600.3730 - val_mae: 21600.3730 - val_mse: 499385248.0000\n",
      "Epoch 353/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16230.7285 - mae: 16230.7285 - mse: 652238464.0000 - val_loss: 7344.9097 - val_mae: 7344.9097 - val_mse: 149233504.0000\n",
      "Epoch 354/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 12366.8965 - mae: 12366.8965 - mse: 561023936.0000 - val_loss: 14686.7822 - val_mae: 14686.7822 - val_mse: 262984944.0000\n",
      "Epoch 355/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18855.3242 - mae: 18855.3242 - mse: 858032000.0000 - val_loss: 12286.7168 - val_mae: 12286.7168 - val_mse: 209478672.0000\n",
      "Epoch 356/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14939.0967 - mae: 14939.0967 - mse: 669985472.0000 - val_loss: 5927.8662 - val_mae: 5927.8662 - val_mse: 167729984.0000\n",
      "Epoch 357/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22349.8203 - mae: 22349.8203 - mse: 984069504.0000 - val_loss: 20997.3828 - val_mae: 20997.3828 - val_mse: 585430528.0000\n",
      "Epoch 358/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17882.4609 - mae: 17882.4609 - mse: 742799808.0000 - val_loss: 5650.5840 - val_mae: 5650.5840 - val_mse: 163937440.0000\n",
      "Epoch 359/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18300.0898 - mae: 18300.0898 - mse: 745407296.0000 - val_loss: 18109.3184 - val_mae: 18109.3184 - val_mse: 472437792.0000\n",
      "Epoch 360/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18358.2012 - mae: 18358.2012 - mse: 792307904.0000 - val_loss: 53716.0430 - val_mae: 53716.0430 - val_mse: 3027871744.0000\n",
      "Epoch 361/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 26186.5020 - mae: 26186.5020 - mse: 1166477056.0000 - val_loss: 10341.1152 - val_mae: 10341.1152 - val_mse: 177076592.0000\n",
      "Epoch 362/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17940.6914 - mae: 17940.6914 - mse: 730106688.0000 - val_loss: 14800.5576 - val_mae: 14800.5576 - val_mse: 362107904.0000\n",
      "Epoch 363/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 14222.4541 - mae: 14222.4541 - mse: 602876864.0000 - val_loss: 30428.7422 - val_mae: 30428.7422 - val_mse: 967734464.0000\n",
      "Epoch 364/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17861.0449 - mae: 17861.0449 - mse: 748446464.0000 - val_loss: 17797.3516 - val_mae: 17797.3516 - val_mse: 460752416.0000\n",
      "Epoch 365/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14502.5371 - mae: 14502.5371 - mse: 610684736.0000 - val_loss: 5814.7354 - val_mae: 5814.7354 - val_mse: 145578144.0000\n",
      "Epoch 366/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 12895.9756 - mae: 12895.9756 - mse: 567819904.0000 - val_loss: 9464.6387 - val_mae: 9464.6387 - val_mse: 224734656.0000\n",
      "Epoch 367/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20112.8242 - mae: 20112.8242 - mse: 851706048.0000 - val_loss: 37092.8164 - val_mae: 37092.8164 - val_mse: 1438282880.0000\n",
      "Epoch 368/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20480.9102 - mae: 20480.9102 - mse: 871003776.0000 - val_loss: 10877.5283 - val_mae: 10877.5283 - val_mse: 184464352.0000\n",
      "Epoch 369/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15347.5186 - mae: 15347.5186 - mse: 648212096.0000 - val_loss: 27430.9941 - val_mae: 27430.9941 - val_mse: 788532032.0000\n",
      "Epoch 370/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14649.5430 - mae: 14649.5430 - mse: 627057344.0000 - val_loss: 7164.5063 - val_mae: 7164.5063 - val_mse: 146612048.0000\n",
      "Epoch 371/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14234.2197 - mae: 14234.2197 - mse: 593040448.0000 - val_loss: 6893.8911 - val_mae: 6893.8911 - val_mse: 145464672.0000\n",
      "Epoch 372/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13660.7578 - mae: 13660.7578 - mse: 598556224.0000 - val_loss: 8277.9922 - val_mae: 8277.9922 - val_mse: 201045216.0000\n",
      "Epoch 373/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15346.3975 - mae: 15346.3975 - mse: 668670528.0000 - val_loss: 30103.6387 - val_mae: 30103.6387 - val_mse: 947450176.0000\n",
      "Epoch 374/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16343.1230 - mae: 16343.1230 - mse: 680670528.0000 - val_loss: 23236.8262 - val_mae: 23236.8262 - val_mse: 572620736.0000\n",
      "Epoch 375/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20003.0957 - mae: 20003.0957 - mse: 820166528.0000 - val_loss: 12160.4443 - val_mae: 12160.4443 - val_mse: 206082096.0000\n",
      "Epoch 376/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 37289.3164 - mae: 37289.3164 - mse: 2062540160.0000 - val_loss: 54306.2617 - val_mae: 54306.2617 - val_mse: 3089735680.0000\n",
      "Epoch 377/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 39468.2539 - mae: 39468.2539 - mse: 2315229440.0000 - val_loss: 42853.9766 - val_mae: 42853.9766 - val_mse: 1977613696.0000\n",
      "Epoch 378/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18953.0703 - mae: 18953.0703 - mse: 767771712.0000 - val_loss: 14605.8594 - val_mae: 14605.8594 - val_mse: 354498976.0000\n",
      "Epoch 379/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16335.3281 - mae: 16335.3281 - mse: 653938112.0000 - val_loss: 13711.6543 - val_mae: 13711.6543 - val_mse: 328335200.0000\n",
      "Epoch 380/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17176.6191 - mae: 17176.6191 - mse: 692973248.0000 - val_loss: 24864.3047 - val_mae: 24864.3047 - val_mse: 651109632.0000\n",
      "Epoch 381/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17558.8750 - mae: 17558.8750 - mse: 720534592.0000 - val_loss: 18098.5918 - val_mae: 18098.5918 - val_mse: 469664448.0000\n",
      "Epoch 382/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15613.8096 - mae: 15613.8096 - mse: 658179072.0000 - val_loss: 15394.3818 - val_mae: 15394.3818 - val_mse: 280780096.0000\n",
      "Epoch 383/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13934.5596 - mae: 13934.5596 - mse: 606915456.0000 - val_loss: 12394.5400 - val_mae: 12394.5400 - val_mse: 210244160.0000\n",
      "Epoch 384/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 12654.3623 - mae: 12654.3623 - mse: 550973184.0000 - val_loss: 25745.2578 - val_mae: 25745.2578 - val_mse: 696532608.0000\n",
      "Epoch 385/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17303.4043 - mae: 17303.4043 - mse: 694570432.0000 - val_loss: 11514.5557 - val_mae: 11514.5557 - val_mse: 193969648.0000\n",
      "Epoch 386/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20346.6523 - mae: 20346.6523 - mse: 958335808.0000 - val_loss: 22550.6953 - val_mae: 22550.6953 - val_mse: 541037120.0000\n",
      "Epoch 387/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18515.3066 - mae: 18515.3066 - mse: 772445312.0000 - val_loss: 22340.9785 - val_mae: 22340.9785 - val_mse: 640195456.0000\n",
      "Epoch 388/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17436.4414 - mae: 17436.4414 - mse: 711538880.0000 - val_loss: 9613.1963 - val_mae: 9613.1963 - val_mse: 165759696.0000\n",
      "Epoch 389/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17182.8418 - mae: 17182.8418 - mse: 706537536.0000 - val_loss: 31832.7910 - val_mae: 31832.7910 - val_mse: 1058260352.0000\n",
      "Epoch 390/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16529.3906 - mae: 16529.3906 - mse: 661734336.0000 - val_loss: 5093.9268 - val_mae: 5093.9268 - val_mse: 150271376.0000\n",
      "Epoch 391/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24228.4922 - mae: 24228.4922 - mse: 1115888000.0000 - val_loss: 7721.0483 - val_mae: 7721.0483 - val_mse: 189769696.0000\n",
      "Epoch 392/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16102.3086 - mae: 16102.3086 - mse: 638101888.0000 - val_loss: 22113.9121 - val_mae: 22113.9121 - val_mse: 521483072.0000\n",
      "Epoch 393/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15159.2861 - mae: 15159.2861 - mse: 615440000.0000 - val_loss: 14924.8398 - val_mae: 14924.8398 - val_mse: 362391520.0000\n",
      "Epoch 394/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 24269.3301 - mae: 24269.3301 - mse: 1035936384.0000 - val_loss: 7865.1416 - val_mae: 7865.1416 - val_mse: 148551648.0000\n",
      "Epoch 395/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16142.4521 - mae: 16142.4521 - mse: 641768640.0000 - val_loss: 35931.2500 - val_mae: 35931.2500 - val_mse: 1349097600.0000\n",
      "Epoch 396/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 14308.7197 - mae: 14308.7197 - mse: 611739840.0000 - val_loss: 25759.8496 - val_mae: 25759.8496 - val_mse: 697291072.0000\n",
      "Epoch 397/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18716.4707 - mae: 18716.4707 - mse: 748664960.0000 - val_loss: 21284.8340 - val_mae: 21284.8340 - val_mse: 485750080.0000\n",
      "Epoch 398/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27616.7559 - mae: 27616.7559 - mse: 1285597440.0000 - val_loss: 18738.3965 - val_mae: 18738.3965 - val_mse: 491439104.0000\n",
      "Epoch 399/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 16397.3652 - mae: 16397.3652 - mse: 626776128.0000 - val_loss: 6138.8101 - val_mae: 6138.8101 - val_mse: 141495408.0000\n",
      "Epoch 400/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23062.7070 - mae: 23062.7070 - mse: 973457280.0000 - val_loss: 17183.4805 - val_mae: 17183.4805 - val_mse: 435460384.0000\n",
      "Epoch 401/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20287.0078 - mae: 20287.0078 - mse: 831647360.0000 - val_loss: 53968.6484 - val_mae: 53968.6484 - val_mse: 3028762368.0000\n",
      "Epoch 402/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 31134.0508 - mae: 31134.0508 - mse: 1481944832.0000 - val_loss: 11890.9082 - val_mae: 11890.9082 - val_mse: 199884832.0000\n",
      "Epoch 403/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17727.5762 - mae: 17727.5762 - mse: 690289536.0000 - val_loss: 19427.7441 - val_mae: 19427.7441 - val_mse: 411662560.0000\n",
      "Epoch 404/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13764.4004 - mae: 13764.4004 - mse: 593574912.0000 - val_loss: 5109.5967 - val_mae: 5109.5967 - val_mse: 146229792.0000\n",
      "Epoch 405/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14093.0957 - mae: 14093.0957 - mse: 582290048.0000 - val_loss: 26374.4609 - val_mae: 26374.4609 - val_mse: 730024768.0000\n",
      "Epoch 406/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20298.8945 - mae: 20298.8945 - mse: 796572544.0000 - val_loss: 46460.6992 - val_mae: 46460.6992 - val_mse: 2296838912.0000\n",
      "Epoch 407/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18953.6562 - mae: 18953.6562 - mse: 786737920.0000 - val_loss: 11813.0107 - val_mae: 11813.0107 - val_mse: 274597280.0000\n",
      "Epoch 408/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16846.4082 - mae: 16846.4082 - mse: 663846016.0000 - val_loss: 12972.8086 - val_mae: 12972.8086 - val_mse: 221040704.0000\n",
      "Epoch 409/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16058.9102 - mae: 16058.9102 - mse: 650473792.0000 - val_loss: 30459.7891 - val_mae: 30459.7891 - val_mse: 969316224.0000\n",
      "Epoch 410/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18911.0371 - mae: 18911.0371 - mse: 741903040.0000 - val_loss: 22768.3887 - val_mae: 22768.3887 - val_mse: 550458944.0000\n",
      "Epoch 411/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17666.6816 - mae: 17666.6816 - mse: 709375040.0000 - val_loss: 10426.8691 - val_mae: 10426.8691 - val_mse: 175408464.0000\n",
      "Epoch 412/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19293.0820 - mae: 19293.0820 - mse: 780044288.0000 - val_loss: 8724.0234 - val_mae: 8724.0234 - val_mse: 205715248.0000\n",
      "Epoch 413/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21005.3691 - mae: 21005.3691 - mse: 904739200.0000 - val_loss: 43381.9844 - val_mae: 43381.9844 - val_mse: 1968381696.0000\n",
      "Epoch 414/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16860.7656 - mae: 16860.7656 - mse: 696553792.0000 - val_loss: 22667.6504 - val_mae: 22667.6504 - val_mse: 545833536.0000\n",
      "Epoch 415/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 18748.9316 - mae: 18748.9316 - mse: 801356544.0000 - val_loss: 28266.7227 - val_mae: 28266.7227 - val_mse: 937406912.0000\n",
      "Epoch 416/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17689.1543 - mae: 17689.1543 - mse: 788070784.0000 - val_loss: 10781.9316 - val_mae: 10781.9316 - val_mse: 180516608.0000\n",
      "Epoch 417/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22638.9805 - mae: 22638.9805 - mse: 990899072.0000 - val_loss: 8779.2412 - val_mae: 8779.2412 - val_mse: 154849472.0000\n",
      "Epoch 418/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14204.6602 - mae: 14204.6602 - mse: 588277376.0000 - val_loss: 8206.0840 - val_mae: 8206.0840 - val_mse: 195853760.0000\n",
      "Epoch 419/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16236.1758 - mae: 16236.1758 - mse: 716474304.0000 - val_loss: 33981.1289 - val_mae: 33981.1289 - val_mse: 1206129792.0000\n",
      "Epoch 420/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17127.7930 - mae: 17127.7930 - mse: 734536000.0000 - val_loss: 10488.2275 - val_mae: 10488.2275 - val_mse: 175889008.0000\n",
      "Epoch 421/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15380.9668 - mae: 15380.9668 - mse: 641983488.0000 - val_loss: 5177.0796 - val_mae: 5177.0796 - val_mse: 142766208.0000\n",
      "Epoch 422/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18984.3281 - mae: 18984.3281 - mse: 793707776.0000 - val_loss: 29717.8262 - val_mae: 29717.8262 - val_mse: 1020805760.0000\n",
      "Epoch 423/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18042.8945 - mae: 18042.8945 - mse: 712469824.0000 - val_loss: 16927.7383 - val_mae: 16927.7383 - val_mse: 325319648.0000\n",
      "Epoch 424/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14781.6787 - mae: 14781.6787 - mse: 601994048.0000 - val_loss: 27429.1504 - val_mae: 27429.1504 - val_mse: 889944960.0000\n",
      "Epoch 425/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 18345.2422 - mae: 18345.2422 - mse: 697250112.0000 - val_loss: 13347.4766 - val_mae: 13347.4766 - val_mse: 228580000.0000\n",
      "Epoch 426/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21247.5371 - mae: 21247.5371 - mse: 869328064.0000 - val_loss: 35330.9844 - val_mae: 35330.9844 - val_mse: 1303919104.0000\n",
      "Epoch 427/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22529.8594 - mae: 22529.8594 - mse: 986860416.0000 - val_loss: 9339.4922 - val_mae: 9339.4922 - val_mse: 216488096.0000\n",
      "Epoch 428/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16571.9004 - mae: 16571.9004 - mse: 669947072.0000 - val_loss: 15144.6621 - val_mae: 15144.6621 - val_mse: 272838784.0000\n",
      "Epoch 429/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21517.1895 - mae: 21517.1895 - mse: 888929536.0000 - val_loss: 8881.5205 - val_mae: 8881.5205 - val_mse: 155184224.0000\n",
      "Epoch 430/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21439.1309 - mae: 21439.1309 - mse: 849584768.0000 - val_loss: 22773.6270 - val_mae: 22773.6270 - val_mse: 656173696.0000\n",
      "Epoch 431/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13980.3623 - mae: 13980.3623 - mse: 562191424.0000 - val_loss: 10482.6201 - val_mae: 10482.6201 - val_mse: 175306544.0000\n",
      "Epoch 432/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18502.4844 - mae: 18502.4844 - mse: 747410112.0000 - val_loss: 17476.4336 - val_mae: 17476.4336 - val_mse: 342793472.0000\n",
      "Epoch 433/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15197.4434 - mae: 15197.4434 - mse: 607272384.0000 - val_loss: 5194.0684 - val_mae: 5194.0684 - val_mse: 141440000.0000\n",
      "Epoch 434/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 14544.9951 - mae: 14544.9951 - mse: 570724352.0000 - val_loss: 9795.5967 - val_mae: 9795.5967 - val_mse: 165587840.0000\n",
      "Epoch 435/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19571.3828 - mae: 19571.3828 - mse: 784287680.0000 - val_loss: 18155.5215 - val_mae: 18155.5215 - val_mse: 365471616.0000\n",
      "Epoch 436/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 12866.9688 - mae: 12866.9688 - mse: 532642400.0000 - val_loss: 9879.8145 - val_mae: 9879.8145 - val_mse: 227054160.0000\n",
      "Epoch 437/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20443.9922 - mae: 20443.9922 - mse: 858805568.0000 - val_loss: 15443.7852 - val_mae: 15443.7852 - val_mse: 280822720.0000\n",
      "Epoch 438/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18172.0059 - mae: 18172.0059 - mse: 718555456.0000 - val_loss: 20675.7891 - val_mae: 20675.7891 - val_mse: 460012864.0000\n",
      "Epoch 439/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22773.7812 - mae: 22773.7812 - mse: 919310784.0000 - val_loss: 14517.1201 - val_mae: 14517.1201 - val_mse: 346685248.0000\n",
      "Epoch 440/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14733.2432 - mae: 14733.2432 - mse: 593464576.0000 - val_loss: 30202.0273 - val_mae: 30202.0273 - val_mse: 952944768.0000\n",
      "Epoch 441/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16020.2266 - mae: 16020.2266 - mse: 592130816.0000 - val_loss: 21462.6465 - val_mae: 21462.6465 - val_mse: 492615648.0000\n",
      "Epoch 442/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14441.4941 - mae: 14441.4941 - mse: 585958144.0000 - val_loss: 13271.6211 - val_mae: 13271.6211 - val_mse: 226280800.0000\n",
      "Epoch 443/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18389.8398 - mae: 18389.8398 - mse: 721053120.0000 - val_loss: 9831.6562 - val_mae: 9831.6562 - val_mse: 225556992.0000\n",
      "Epoch 444/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14207.3857 - mae: 14207.3857 - mse: 560717568.0000 - val_loss: 5112.3242 - val_mae: 5112.3242 - val_mse: 141031840.0000\n",
      "Epoch 445/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15410.4062 - mae: 15410.4062 - mse: 595049600.0000 - val_loss: 18874.8809 - val_mae: 18874.8809 - val_mse: 492693568.0000\n",
      "Epoch 446/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19480.0508 - mae: 19480.0508 - mse: 765565568.0000 - val_loss: 9848.1934 - val_mae: 9848.1934 - val_mse: 225663232.0000\n",
      "Epoch 447/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13199.1729 - mae: 13199.1729 - mse: 553611392.0000 - val_loss: 22458.7656 - val_mae: 22458.7656 - val_mse: 536034400.0000\n",
      "Epoch 448/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19287.2910 - mae: 19287.2910 - mse: 787316032.0000 - val_loss: 43270.7461 - val_mae: 43270.7461 - val_mse: 2007254784.0000\n",
      "Epoch 449/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 19972.1855 - mae: 19972.1855 - mse: 812418752.0000 - val_loss: 14556.0625 - val_mae: 14556.0625 - val_mse: 347005088.0000\n",
      "Epoch 450/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 12849.0381 - mae: 12849.0381 - mse: 541849920.0000 - val_loss: 13913.1484 - val_mae: 13913.1484 - val_mse: 240817920.0000\n",
      "Epoch 451/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13080.4424 - mae: 13080.4424 - mse: 569824832.0000 - val_loss: 14996.1914 - val_mae: 14996.1914 - val_mse: 359979136.0000\n",
      "Epoch 452/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 16611.1426 - mae: 16611.1426 - mse: 631862336.0000 - val_loss: 33436.7695 - val_mae: 33436.7695 - val_mse: 1167630592.0000\n",
      "Epoch 453/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18290.3086 - mae: 18290.3086 - mse: 729261760.0000 - val_loss: 41590.3242 - val_mae: 41590.3242 - val_mse: 1808592256.0000\n",
      "Epoch 454/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15546.5137 - mae: 15546.5137 - mse: 636112512.0000 - val_loss: 16098.5137 - val_mae: 16098.5137 - val_mse: 394537696.0000\n",
      "Epoch 455/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 20325.6309 - mae: 20325.6309 - mse: 819476416.0000 - val_loss: 5958.6201 - val_mae: 5958.6201 - val_mse: 136752928.0000\n",
      "Epoch 456/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13591.1553 - mae: 13591.1553 - mse: 544062080.0000 - val_loss: 12286.8818 - val_mae: 12286.8818 - val_mse: 205210464.0000\n",
      "Epoch 457/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16464.8652 - mae: 16464.8652 - mse: 646148608.0000 - val_loss: 8206.8145 - val_mae: 8206.8145 - val_mse: 147093504.0000\n",
      "Epoch 458/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18202.6992 - mae: 18202.6992 - mse: 755951680.0000 - val_loss: 17143.8809 - val_mae: 17143.8809 - val_mse: 331608096.0000\n",
      "Epoch 459/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14356.9834 - mae: 14356.9834 - mse: 568293568.0000 - val_loss: 23338.9492 - val_mae: 23338.9492 - val_mse: 679577536.0000\n",
      "Epoch 460/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 12991.7930 - mae: 12991.7930 - mse: 530692640.0000 - val_loss: 15297.4521 - val_mae: 15297.4521 - val_mse: 276448800.0000\n",
      "Epoch 461/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 31732.0078 - mae: 31732.0078 - mse: 1591165696.0000 - val_loss: 18216.5977 - val_mae: 18216.5977 - val_mse: 466867936.0000\n",
      "Epoch 462/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15847.0488 - mae: 15847.0488 - mse: 605548160.0000 - val_loss: 21153.6504 - val_mae: 21153.6504 - val_mse: 479447744.0000\n",
      "Epoch 463/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16184.1367 - mae: 16184.1367 - mse: 642843456.0000 - val_loss: 6663.3335 - val_mae: 6663.3335 - val_mse: 137405312.0000\n",
      "Epoch 464/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19330.5391 - mae: 19330.5391 - mse: 725448960.0000 - val_loss: 14217.6279 - val_mae: 14217.6279 - val_mse: 247950272.0000\n",
      "Epoch 465/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17697.1387 - mae: 17697.1387 - mse: 679191424.0000 - val_loss: 11456.5361 - val_mae: 11456.5361 - val_mse: 260952816.0000\n",
      "Epoch 466/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16174.4785 - mae: 16174.4785 - mse: 612398336.0000 - val_loss: 14831.6045 - val_mae: 14831.6045 - val_mse: 263681216.0000\n",
      "Epoch 467/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 17506.5117 - mae: 17506.5117 - mse: 719843008.0000 - val_loss: 11595.8711 - val_mae: 11595.8711 - val_mse: 264281072.0000\n",
      "Epoch 468/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 11817.6680 - mae: 11817.6680 - mse: 488220896.0000 - val_loss: 6330.6260 - val_mae: 6330.6260 - val_mse: 136119760.0000\n",
      "Epoch 469/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 25125.7129 - mae: 25125.7129 - mse: 1120408576.0000 - val_loss: 17772.0215 - val_mae: 17772.0215 - val_mse: 352035072.0000\n",
      "Epoch 470/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 21705.8496 - mae: 21705.8496 - mse: 886617984.0000 - val_loss: 35747.8281 - val_mae: 35747.8281 - val_mse: 1334403968.0000\n",
      "Epoch 471/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 27433.6055 - mae: 27433.6055 - mse: 1238045056.0000 - val_loss: 25675.8047 - val_mae: 25675.8047 - val_mse: 793241024.0000\n",
      "Epoch 472/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20323.7930 - mae: 20323.7930 - mse: 786489088.0000 - val_loss: 19605.7891 - val_mae: 19605.7891 - val_mse: 417579712.0000\n",
      "Epoch 473/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13211.2363 - mae: 13211.2363 - mse: 521135584.0000 - val_loss: 22251.2930 - val_mae: 22251.2930 - val_mse: 526540832.0000\n",
      "Epoch 474/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16485.7793 - mae: 16485.7793 - mse: 664308480.0000 - val_loss: 5089.0435 - val_mae: 5089.0435 - val_mse: 146116608.0000\n",
      "Epoch 475/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15708.3809 - mae: 15708.3809 - mse: 611886208.0000 - val_loss: 9299.2568 - val_mae: 9299.2568 - val_mse: 157348656.0000\n",
      "Epoch 476/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13561.4209 - mae: 13561.4209 - mse: 551690304.0000 - val_loss: 10918.3330 - val_mae: 10918.3330 - val_mse: 247484384.0000\n",
      "Epoch 477/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16628.1055 - mae: 16628.1055 - mse: 679934720.0000 - val_loss: 23895.8652 - val_mae: 23895.8652 - val_mse: 602924800.0000\n",
      "Epoch 478/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 22472.3926 - mae: 22472.3926 - mse: 933849216.0000 - val_loss: 40631.1094 - val_mae: 40631.1094 - val_mse: 1783610624.0000\n",
      "Epoch 479/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 16016.0986 - mae: 16016.0986 - mse: 699793984.0000 - val_loss: 5388.4160 - val_mae: 5388.4160 - val_mse: 135829472.0000\n",
      "Epoch 480/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 18378.9082 - mae: 18378.9082 - mse: 722142016.0000 - val_loss: 17671.1973 - val_mae: 17671.1973 - val_mse: 348385376.0000\n",
      "Epoch 481/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15005.3174 - mae: 15005.3174 - mse: 555000896.0000 - val_loss: 21115.1270 - val_mae: 21115.1270 - val_mse: 477521696.0000\n",
      "Epoch 482/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20468.2129 - mae: 20468.2129 - mse: 811762560.0000 - val_loss: 7214.0625 - val_mae: 7214.0625 - val_mse: 138752576.0000\n",
      "Epoch 483/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 13356.3418 - mae: 13356.3418 - mse: 529446080.0000 - val_loss: 21507.1504 - val_mae: 21507.1504 - val_mse: 494034720.0000\n",
      "Epoch 484/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 15816.1523 - mae: 15816.1523 - mse: 631907136.0000 - val_loss: 5246.5874 - val_mae: 5246.5874 - val_mse: 135982816.0000\n",
      "Epoch 485/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 19134.4238 - mae: 19134.4238 - mse: 721655168.0000 - val_loss: 23050.4883 - val_mae: 23050.4883 - val_mse: 664386368.0000\n",
      "Epoch 486/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 23976.6484 - mae: 23976.6484 - mse: 978043648.0000 - val_loss: 14420.5830 - val_mae: 14420.5830 - val_mse: 252489104.0000\n",
      "Epoch 487/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20524.7812 - mae: 20524.7812 - mse: 793858368.0000 - val_loss: 17419.8047 - val_mae: 17419.8047 - val_mse: 436786176.0000\n",
      "Epoch 488/500\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 18761.4375 - mae: 18761.4375 - mse: 728481728.0000 - val_loss: 14238.5938 - val_mae: 14238.5938 - val_mse: 334941952.0000\n",
      "Epoch 489/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 18923.1348 - mae: 18923.1348 - mse: 786063104.0000 - val_loss: 20759.7930 - val_mae: 20759.7930 - val_mse: 462711520.0000\n",
      "Epoch 490/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21617.2246 - mae: 21617.2246 - mse: 907449280.0000 - val_loss: 10692.2510 - val_mae: 10692.2510 - val_mse: 175904432.0000\n",
      "Epoch 491/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13667.1914 - mae: 13667.1914 - mse: 540732800.0000 - val_loss: 4917.0889 - val_mae: 4917.0889 - val_mse: 141534832.0000\n",
      "Epoch 492/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13450.4805 - mae: 13450.4805 - mse: 534718624.0000 - val_loss: 7756.8145 - val_mae: 7756.8145 - val_mse: 182224016.0000\n",
      "Epoch 493/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13333.0078 - mae: 13333.0078 - mse: 533018144.0000 - val_loss: 6465.5591 - val_mae: 6465.5591 - val_mse: 162183360.0000\n",
      "Epoch 494/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14212.6807 - mae: 14212.6807 - mse: 551455808.0000 - val_loss: 25990.6973 - val_mae: 25990.6973 - val_mse: 709495104.0000\n",
      "Epoch 495/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15193.9473 - mae: 15193.9473 - mse: 579007872.0000 - val_loss: 7326.0781 - val_mae: 7326.0781 - val_mse: 138573008.0000\n",
      "Epoch 496/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 15794.7520 - mae: 15794.7520 - mse: 617708736.0000 - val_loss: 5122.7085 - val_mae: 5122.7085 - val_mse: 135739008.0000\n",
      "Epoch 497/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 13698.9473 - mae: 13698.9473 - mse: 550721216.0000 - val_loss: 8221.2061 - val_mae: 8221.2061 - val_mse: 189603360.0000\n",
      "Epoch 498/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 20290.4141 - mae: 20290.4141 - mse: 839308544.0000 - val_loss: 6604.6123 - val_mae: 6604.6123 - val_mse: 134976608.0000\n",
      "Epoch 499/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 14505.4229 - mae: 14505.4229 - mse: 549580800.0000 - val_loss: 15001.9902 - val_mae: 15001.9902 - val_mse: 267551888.0000\n",
      "Epoch 500/500\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 21869.5586 - mae: 21869.5586 - mse: 914168832.0000 - val_loss: 14918.8750 - val_mae: 14918.8750 - val_mse: 265281840.0000\n"
     ]
    }
   ],
   "source": [
    "# construct the LSTM model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(128, input_shape=(1, WINDOW), activation='relu'),\n",
    "    #tf.keras.layers.LSTM(128, activation='relu'),\n",
    "    #tf.keras.layers.Dense(64, activation='relu'),\n",
    "    #tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(HORIZON)\n",
    "])\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='mae', optimizer='adam', metrics=['mae', 'mse'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs=500,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1375/1375 [00:56<00:00, 24.36it/s]\n",
      "100%|| 321/321 [00:12<00:00, 24.97it/s]\n"
     ]
    }
   ],
   "source": [
    "trained_model = tf.keras.models.load_model('./purchase_lstm_forecast_model.h5')\n",
    "\n",
    "predictions = []\n",
    "print(np.shape(x_train[0]))\n",
    "# predict on training data\n",
    "for val in tqdm(x_train):\n",
    "    yhat = trained_model.predict(np.expand_dims(val, axis=0), verbose=0)\n",
    "    predictions.append(yhat)\n",
    "\n",
    "# predict on validation data\n",
    "for val in tqdm(x_val):\n",
    "    yhat = trained_model.predict(np.expand_dims(val, axis=0), verbose=0)\n",
    "    predictions.append(yhat)\n",
    "\n",
    "predictions = [p[0][0] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create forecast\n",
    "forecast = []\n",
    "forecast_dates = []\n",
    "\n",
    "# predict on the last values in validation data, generate initial forecast\n",
    "for i in tqdm(range(WINDOW)):\n",
    "\n",
    "    xvals = x_val[-1][0][i:]\n",
    "\n",
    "    for j in range(len(forecast)):\n",
    "        xvals = np.insert(xvals, j, forecast[j])\n",
    "    xvals = np.expand_dims(xvals, axis=0)\n",
    "\n",
    "    yhat = trained_model.predict(np.expand_dims(xvals, axis=0), verbose=0)\n",
    "    forecast.append(yhat[0,0])\n",
    "\n",
    "forecast_dates.append(dates[-1] + timedelta(days=1))\n",
    "for i in range(WINDOW-1):\n",
    "    forecast_dates.append(forecast_dates[-1] + timedelta(days=1))\n",
    "\n",
    "for i in tqdm(range(365)):\n",
    "    # take last N previous forecast values\n",
    "    prev_vals = forecast[-WINDOW:]\n",
    "    prev_vals = np.expand_dims(prev_vals, axis=0)\n",
    "\n",
    "\n",
    "    yhat = trained_model.predict(np.expand_dims(prev_vals, axis=0), verbose=0)\n",
    "    forecast.append(yhat[0,0])\n",
    "    forecast_dates.append(forecast_dates[-1] + timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=dates, y=dt, name='Actual', line=dict(color='#1f77b4')))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=dates[WINDOW:], y=predictions, name='Predicted', line=dict(color='#d62728', dash=\"dash\")))\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=forecast_dates, y=forecast, name='Forecast', line=dict(color='#2ca02c', dash=\"dash\")))\n",
    "\n",
    "fig.update_layout(\n",
    "    template='plotly_dark',\n",
    "    title={'text': \"TSW Cumulative Spending\", 'y':0.9,'x':0.5,'xanchor': 'center','yanchor': 'top'},\n",
    "    xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Total Spent ($)\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "actual = np.asarray(np.concatenate((y_train, y_val)))\n",
    "predicted = np.asarray(predictions)\n",
    "\n",
    "MSE = np.mean((predicted - actual)**2)\n",
    "RMSE = np.sqrt(MSE)\n",
    "print('mse -->', MSE)\n",
    "print('rmse -->', RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the saved model\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "MODEL_DIR = tempfile.gettempdir()\n",
    "VERSION = 1\n",
    "\n",
    "export_path = os.path.join(MODEL_DIR, f\"purchase_lstm_model_v{VERSION}\")\n",
    "print(f\"Export model to ---> {export_path}\")\n",
    "\n",
    "tf.keras.models.save_model(\n",
    "    trained_model,\n",
    "    export_path,\n",
    "    overwrite=True,\n",
    "    include_optimizer=True,\n",
    "    save_format=None,\n",
    "    signatures=None,\n",
    "    options=None\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9a31608ab0afb6106b103885e5e53a395ed23843c8eba78daefa9379a753e79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
