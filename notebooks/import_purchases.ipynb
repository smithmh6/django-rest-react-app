{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import initializer\n",
    "import kernel_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import datetime as dt\n",
    "from django.contrib.auth.models import User\n",
    "from django.db import transaction\n",
    "from django.core.exceptions import MultipleObjectsReturned, ObjectDoesNotExist\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytz as tz\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import local files\n",
    "from purchasing.models import *\n",
    "from purchasing.serializers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  requested requested_by_id   modified modified_by_id vendor_id  \\\n",
      "0  1000002  8/30/2019          hsmith  8/30/2019         hsmith    Amazon   \n",
      "1  1000006  8/30/2019          acable  8/30/2019         acable  Thorlabs   \n",
      "2  1000007  8/30/2019          acable  8/30/2019         acable  Thorlabs   \n",
      "3  1000008  8/30/2019          acable  8/30/2019         acable  Thorlabs   \n",
      "4  1000009  8/30/2019         afisher  8/30/2019        afisher    Airgas   \n",
      "5  1000010  8/30/2019         afisher  8/30/2019        afisher       VWR   \n",
      "6  1000011  8/30/2019         afisher  8/30/2019        afisher       VWR   \n",
      "7  1000012  8/30/2019         afisher  8/30/2019        afisher    Amazon   \n",
      "8  1000013  8/30/2019         afisher  8/30/2019        afisher       VWR   \n",
      "9  1000014  8/30/2019         afisher  8/30/2019        afisher       VWR   \n",
      "\n",
      "                                         description  product_no package_size  \\\n",
      "0                                       X-acto knife       X3311         None   \n",
      "1              3-axis Piezo Controller (closed loop)      BPC303         None   \n",
      "2                                   Thorlabs NanoMax      MAX381         None   \n",
      "3                          3-axis Stepper Controller      BSC203         None   \n",
      "4                                 UHP Nitrogen tanks      UN1066         None   \n",
      "5           Nitrile Examination Glove (case of 1000)   82026-428         None   \n",
      "6                                        Drying Rack   82024-450         None   \n",
      "7                                  Lenovo 130S-11IGM  130S-11IGM         None   \n",
      "8               Labtone Laboratory Cleaning Compound   89030-112         None   \n",
      "9  Low Form Griffin Beaker Sample Kit 25 50 125 2...   75870-432         None   \n",
      "\n",
      "    moq  ...  group_id  category_id  project_id        status  status_id  \\\n",
      "0  None  ...       MAG        Tools        None  Not Approved  Requested   \n",
      "1  None  ...       MAG        CapEx        None     Purchased   Received   \n",
      "2  None  ...       MAG        CapEx        None     Purchased   Received   \n",
      "3  None  ...       MAG        CapEx        None     Purchased   Received   \n",
      "4  None  ...       FAC   Consumable        None     Purchased   Received   \n",
      "5  None  ...       FAC   Consumable        None     Purchased   Received   \n",
      "6  None  ...       FAC    Equipment        None     Purchased   Received   \n",
      "7  None  ...       OMB    Equipment        None     Purchased   Received   \n",
      "8  None  ...        CR   Consumable        None     Purchased   Received   \n",
      "9  None  ...        CR    Equipment        None     Purchased   Received   \n",
      "\n",
      "  po_no   approved_id quote_no qty_received notes  \n",
      "0  None  Not Approved      NaN            2  None  \n",
      "1  None      Approved      NaN            1  None  \n",
      "2  None      Approved      NaN            1  None  \n",
      "3  None      Approved      NaN            1  None  \n",
      "4  None      Approved      NaN            2  None  \n",
      "5  None      Approved      NaN            1  None  \n",
      "6  None      Approved      NaN            1  None  \n",
      "7  None      Approved      NaN            1  None  \n",
      "8  None      Approved      NaN            1  None  \n",
      "9  None      Approved      NaN            2  None  \n",
      "\n",
      "[10 rows x 24 columns]\n",
      "DF Shape ---> rows:  5028   cols:  24\n",
      "['id' 'requested' 'requested_by_id' 'modified' 'modified_by_id'\n",
      " 'vendor_id' 'description' 'product_no' 'package_size' 'moq' 'qty'\n",
      " 'item_cost' 'total_cost' 'product_link' 'group_id' 'category_id'\n",
      " 'project_id' 'status' 'status_id' 'po_no' 'approved_id' 'quote_no'\n",
      " 'qty_received' 'notes']\n"
     ]
    }
   ],
   "source": [
    "# set up file path and read into dataframe\n",
    "data_path = r'C:\\Users\\hsmith\\OneDrive - THORLABS Inc\\Documents - Thorlabs Spectral Works\\Purchasing\\_archive\\merged_purchase_records.csv'\n",
    "\n",
    "# read main purchase list into dataframe\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.where(pd.notnull(df), None)\n",
    "print(df.head(10))\n",
    "rows, cols = df.shape\n",
    "print(\"DF Shape ---> rows: \", rows, \"  cols: \", cols)\n",
    "\n",
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = User.objects.all()\n",
    "all_vendors = Vendor.objects.all()\n",
    "all_categories = Category.objects.all()\n",
    "all_groups = Group.objects.all()\n",
    "all_status = ItemStatus.objects.all()\n",
    "all_approvals = ApprovalStatus.objects.all()\n",
    "all_projects = Project.objects.all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 278 vendors.\n"
     ]
    }
   ],
   "source": [
    "# validate FK objects\n",
    "df_vendors = [str(s) for s in df['vendor_id'].dropna().unique()]\n",
    "df_vendors.sort()\n",
    "print(f\"Found {len(df_vendors)} vendors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vendor_code(v):\n",
    "    try:\n",
    "        v_obj = all_vendors.get(name__icontains=v)\n",
    "        return v_obj.vendor_code\n",
    "    except MultipleObjectsReturned as ex:\n",
    "        try:\n",
    "            v_obj = all_vendors.get(name=v)\n",
    "            return v_obj.vendor_code\n",
    "        except:\n",
    "            return None\n",
    "    except Exception as ex:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size:  12   n_iters:  419  remainder:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 419/419 [44:01<00:00,  6.31s/it] \n"
     ]
    }
   ],
   "source": [
    "# configure settings for importing data\n",
    "batch_size = 12\n",
    "remainder = rows % batch_size\n",
    "n_iters = int(rows/batch_size)\n",
    "print(\"batch size: \", batch_size, \"  n_iters: \", n_iters, \" remainder: \", remainder)\n",
    "\n",
    "start = 0\n",
    "end = batch_size\n",
    "\n",
    "vendor_errors = []\n",
    "\n",
    "logfile = open('logfile.txt', 'w')\n",
    "logfile.write(\"Beginning sync...\\n\")\n",
    "logfile.close()\n",
    "\n",
    "for i in tqdm(range(n_iters)):\n",
    "    batch = []\n",
    "    df_ids = []\n",
    "    with open('logfile.txt', 'a') as logfile:\n",
    "        for j in range(start, end):\n",
    "            batch.append({\n",
    "                'description': str(df['description'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'requested': df['requested'][j],      \n",
    "                'modified': df['modified'][j],\n",
    "                'product_no': str(df['product_no'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'package_size': str(df['package_size'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'moq': str(df['moq'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'item_cost': df['item_cost'][j],\n",
    "                'qty': df['qty'][j],\n",
    "                'total_cost': df['total_cost'][j],\n",
    "                'product_link': df['product_link'][j],\n",
    "                'qty_received': int(df['qty_received'][j]),\n",
    "                'notes': str(df['notes'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'po_no': str(df['po_no'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'quote_no': str(df['quote_no'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'modified_by': str(df['modified_by_id'][j]),\n",
    "                'requested_by': str(df['requested_by_id'][j]),\n",
    "                'approved': str(df['approved_id'][j]),\n",
    "                'status': str(df['status_id'][j]),\n",
    "                'group_id': str(df['group_id'][j]),\n",
    "                'category': all_categories.get(description=str(df['category_id'][j])).category_code if df['category_id'][j] is not None else None,\n",
    "                'project': all_projects.get(name=str(df['project_id'][j])).project_no if df['project_id'][j] is not None else None,\n",
    "                'vendor': get_vendor_code(str(df['vendor_id'][j])) if df['vendor_id'][j] is not None else None,\n",
    "            })\n",
    "\n",
    "    with open('logfile.txt', 'a') as logfile:\n",
    "        batch_serializer = PurchaseSerializer(data=batch, many=True)\n",
    "        if batch_serializer.is_valid():\n",
    "            try:\n",
    "                with transaction.atomic():\n",
    "                    batch_serializer.save()\n",
    "            except Exception as ex:\n",
    "                logfile.write(f\"ERROR --->  Batch: {i+1}  ID: {df['id'][j]} Upload failed. {str(ex)} \\n\")\n",
    "        else:\n",
    "            logfile.write(\"[SERIALIZER ERRORS] ---> \" + str(batch_serializer.errors) + '\\n')\n",
    "\n",
    "        start += batch_size\n",
    "        end += batch_size\n",
    "\n",
    "        logfile.write(f\"Batch {i+1} of {n_iters} completed..\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# add missing purchases one by one and get error messages\n",
    "err_df = pd.read_csv('./record_errors.csv')\n",
    "err_df = err_df.where(pd.notnull(df), None)\n",
    "\n",
    "with open('err_log.txt', 'w') as err:\n",
    "    for j in tqdm(range(len(err_df['id'].values))):\n",
    "        try:\n",
    "            new_purchase = PurchaseSerializer(data={\n",
    "                'description': str(err_df['description'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'requested': err_df['requested'][j],      \n",
    "                'modified': err_df['modified'][j],\n",
    "                'product_no': str(err_df['product_no'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'package_size': str(err_df['package_size'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'moq': str(err_df['moq'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'item_cost': err_df['item_cost'][j],\n",
    "                'qty': err_df['qty'][j],\n",
    "                'total_cost': err_df['total_cost'][j],\n",
    "                'product_link': err_df['product_link'][j],\n",
    "                'qty_received': int(df['qty_received'][j]),\n",
    "                'notes': str(err_df['notes'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'po_no': str(err_df['po_no'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'quote_no': str(err_df['quote_no'][j]).strip().replace(',', ' ').replace('\\n', ' '),\n",
    "                'modified_by': User.objects.get(username=str(err_df['modified_by_id'][j])),\n",
    "                'requested_by': User.objects.get(username=str(err_df['requested_by_id'][j])),\n",
    "                'approved': str(err_df['approved_id'][j]),\n",
    "                'status': str(err_df['status_id'][j]),\n",
    "                'group_id': str(err_df['group_id'][j]),\n",
    "                'category': all_categories.get(description=str(err_df['category_id'][j])).category_code if err_df['category_id'][j] is not None else None,\n",
    "                'project': all_projects.get(name=str(err_df['project_id'][j])).project_no if err_df['project_id'][j] is not None else None,\n",
    "                'vendor': get_vendor_code(str(err_df['vendor_id'][j])) if err_df['vendor_id'][j] is not None else None,\n",
    "            })\n",
    "            if new_purchase.is_valid():\n",
    "                new_purchase.save()\n",
    "            else:\n",
    "                err.write(str(err_df['id'][j]) + \" ---> \" + str(new_purchase.errors) + '\\n')\n",
    "        except Exception as ex:\n",
    "            err.write(str(err_df['id'][j]) + \" ---> \" + str(ex) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 33/5028 [00:02<07:19, 11.38it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     d_obj \u001b[39m=\u001b[39m Purchase\u001b[39m.\u001b[39mobjects\u001b[39m.\u001b[39mget(description\u001b[39m=\u001b[39md)\n\u001b[0;32m     12\u001b[0m     d_obj\u001b[39m.\u001b[39mrequested \u001b[39m=\u001b[39m requested_dates[i]\n\u001b[1;32m---> 13\u001b[0m     d_obj\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m     14\u001b[0m \u001b[39mexcept\u001b[39;00m MultipleObjectsReturned:\n\u001b[0;32m     15\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\models\\base.py:806\u001b[0m, in \u001b[0;36mModel.save\u001b[1;34m(self, force_insert, force_update, using, update_fields)\u001b[0m\n\u001b[0;32m    803\u001b[0m     \u001b[39mif\u001b[39;00m loaded_fields:\n\u001b[0;32m    804\u001b[0m         update_fields \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m(loaded_fields)\n\u001b[1;32m--> 806\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_base(\n\u001b[0;32m    807\u001b[0m     using\u001b[39m=\u001b[39;49musing,\n\u001b[0;32m    808\u001b[0m     force_insert\u001b[39m=\u001b[39;49mforce_insert,\n\u001b[0;32m    809\u001b[0m     force_update\u001b[39m=\u001b[39;49mforce_update,\n\u001b[0;32m    810\u001b[0m     update_fields\u001b[39m=\u001b[39;49mupdate_fields,\n\u001b[0;32m    811\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\models\\base.py:857\u001b[0m, in \u001b[0;36mModel.save_base\u001b[1;34m(self, raw, force_insert, force_update, using, update_fields)\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m raw:\n\u001b[0;32m    856\u001b[0m         parent_inserted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_parents(\u001b[39mcls\u001b[39m, using, update_fields)\n\u001b[1;32m--> 857\u001b[0m     updated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_table(\n\u001b[0;32m    858\u001b[0m         raw,\n\u001b[0;32m    859\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[0;32m    860\u001b[0m         force_insert \u001b[39mor\u001b[39;49;00m parent_inserted,\n\u001b[0;32m    861\u001b[0m         force_update,\n\u001b[0;32m    862\u001b[0m         using,\n\u001b[0;32m    863\u001b[0m         update_fields,\n\u001b[0;32m    864\u001b[0m     )\n\u001b[0;32m    865\u001b[0m \u001b[39m# Store the database on which the object was saved\u001b[39;00m\n\u001b[0;32m    866\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mdb \u001b[39m=\u001b[39m using\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\models\\base.py:970\u001b[0m, in \u001b[0;36mModel._save_table\u001b[1;34m(self, raw, cls, force_insert, force_update, using, update_fields)\u001b[0m\n\u001b[0;32m    961\u001b[0m values \u001b[39m=\u001b[39m [\n\u001b[0;32m    962\u001b[0m     (\n\u001b[0;32m    963\u001b[0m         f,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m non_pks\n\u001b[0;32m    968\u001b[0m ]\n\u001b[0;32m    969\u001b[0m forced_update \u001b[39m=\u001b[39m update_fields \u001b[39mor\u001b[39;00m force_update\n\u001b[1;32m--> 970\u001b[0m updated \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_update(\n\u001b[0;32m    971\u001b[0m     base_qs, using, pk_val, values, update_fields, forced_update\n\u001b[0;32m    972\u001b[0m )\n\u001b[0;32m    973\u001b[0m \u001b[39mif\u001b[39;00m force_update \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m updated:\n\u001b[0;32m    974\u001b[0m     \u001b[39mraise\u001b[39;00m DatabaseError(\u001b[39m\"\u001b[39m\u001b[39mForced update did not affect any rows.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\models\\base.py:1034\u001b[0m, in \u001b[0;36mModel._do_update\u001b[1;34m(self, base_qs, using, pk_val, values, update_fields, forced_update)\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_meta\u001b[39m.\u001b[39mselect_on_save \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m forced_update:\n\u001b[0;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m   1023\u001b[0m         filtered\u001b[39m.\u001b[39mexists()\n\u001b[0;32m   1024\u001b[0m         \u001b[39mand\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         (filtered\u001b[39m.\u001b[39m_update(values) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m filtered\u001b[39m.\u001b[39mexists())\n\u001b[0;32m   1033\u001b[0m     )\n\u001b[1;32m-> 1034\u001b[0m \u001b[39mreturn\u001b[39;00m filtered\u001b[39m.\u001b[39;49m_update(values) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\models\\query.py:885\u001b[0m, in \u001b[0;36mQuerySet._update\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m    883\u001b[0m query\u001b[39m.\u001b[39mannotations \u001b[39m=\u001b[39m {}\n\u001b[0;32m    884\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result_cache \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 885\u001b[0m \u001b[39mreturn\u001b[39;00m query\u001b[39m.\u001b[39;49mget_compiler(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdb)\u001b[39m.\u001b[39;49mexecute_sql(CURSOR)\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\models\\sql\\compiler.py:1783\u001b[0m, in \u001b[0;36mSQLUpdateCompiler.execute_sql\u001b[1;34m(self, result_type)\u001b[0m\n\u001b[0;32m   1776\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute_sql\u001b[39m(\u001b[39mself\u001b[39m, result_type):\n\u001b[0;32m   1777\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m \u001b[39m    Execute the specified update. Return the number of rows affected by\u001b[39;00m\n\u001b[0;32m   1779\u001b[0m \u001b[39m    the primary update query. The \"primary update query\" is the first\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[39m    non-empty query that is executed. Row counts for any subsequent,\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[39m    related queries are not available.\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1783\u001b[0m     cursor \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mexecute_sql(result_type)\n\u001b[0;32m   1784\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1785\u001b[0m         rows \u001b[39m=\u001b[39m cursor\u001b[39m.\u001b[39mrowcount \u001b[39mif\u001b[39;00m cursor \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\models\\sql\\compiler.py:1361\u001b[0m, in \u001b[0;36mSQLCompiler.execute_sql\u001b[1;34m(self, result_type, chunked_fetch, chunk_size)\u001b[0m\n\u001b[0;32m   1359\u001b[0m     cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection\u001b[39m.\u001b[39mcursor()\n\u001b[0;32m   1360\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1361\u001b[0m     cursor\u001b[39m.\u001b[39;49mexecute(sql, params)\n\u001b[0;32m   1362\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1363\u001b[0m     \u001b[39m# Might fail for server-side cursors (e.g. connection closed)\u001b[39;00m\n\u001b[0;32m   1364\u001b[0m     cursor\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\backends\\utils.py:103\u001b[0m, in \u001b[0;36mCursorDebugWrapper.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute\u001b[39m(\u001b[39mself\u001b[39m, sql, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    102\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug_sql(sql, params, use_last_executed_query\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 103\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mexecute(sql, params)\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\backends\\utils.py:67\u001b[0m, in \u001b[0;36mCursorWrapper.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute\u001b[39m(\u001b[39mself\u001b[39m, sql, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> 67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_with_wrappers(\n\u001b[0;32m     68\u001b[0m         sql, params, many\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, executor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute\n\u001b[0;32m     69\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\backends\\utils.py:80\u001b[0m, in \u001b[0;36mCursorWrapper._execute_with_wrappers\u001b[1;34m(self, sql, params, many, executor)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[39mfor\u001b[39;00m wrapper \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdb\u001b[39m.\u001b[39mexecute_wrappers):\n\u001b[0;32m     79\u001b[0m     executor \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mpartial(wrapper, executor)\n\u001b[1;32m---> 80\u001b[0m \u001b[39mreturn\u001b[39;00m executor(sql, params, many, context)\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\django\\db\\backends\\utils.py:89\u001b[0m, in \u001b[0;36mCursorWrapper._execute\u001b[1;34m(self, sql, params, *ignored_wrapper_args)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcursor\u001b[39m.\u001b[39mexecute(sql)\n\u001b[0;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcursor\u001b[39m.\u001b[39;49mexecute(sql, params)\n",
      "File \u001b[1;32mc:\\Users\\hsmith\\repos\\Production-Tools\\tsw-web-app\\env\\Lib\\site-packages\\mssql\\base.py:619\u001b[0m, in \u001b[0;36mCursorWrapper.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_params \u001b[39m=\u001b[39m params\n\u001b[0;32m    618\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcursor\u001b[39m.\u001b[39;49mexecute(sql, params)\n\u001b[0;32m    620\u001b[0m \u001b[39mexcept\u001b[39;00m Database\u001b[39m.\u001b[39mError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    621\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnection\u001b[39m.\u001b[39m_on_error(e)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from django.utils.timezone import make_aware\n",
    "\n",
    "requested_dates = [datetime.strptime(dt, \"%m/%d/%Y\")\n",
    "                    for dt in df['requested'].values]\n",
    "requested_dates = [make_aware(t) for t in requested_dates]\n",
    "\n",
    "with open('record_errors.csv', 'w', encoding='utf-8') as err:\n",
    "    for i, d in enumerate(tqdm(df['description'].values)):\n",
    "        try:\n",
    "            d_obj = Purchase.objects.get(description=d)\n",
    "            d_obj.requested = requested_dates[i]\n",
    "            d_obj.save()\n",
    "        except MultipleObjectsReturned:\n",
    "            pass\n",
    "        except Exception as ex:\n",
    "            err.write(str(ex) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['description' 'product_no' '(No column name)']\n",
      "344\n",
      "1 micron Pall Emflon filter 0 3\n",
      "12mm EFL f/1.4 for 2/3\" C-Mount Format Cameras with Lock 1 2\n",
      "30mm Cage Right-angle kinematic OAP Mirror Mount 3 2\n",
      "5 Port Switch 2 3\n",
      "50 mm Square Construction Rail 20\" Long 1/4\"-20 Taps 1 2\n",
      "50mm EFL F/2.8 for 2/3\" C-Mount Format Cameras with Lock 1 2\n",
      "6.5X Zoom Lens 1 3\n",
      "8-32 Cap Screw Kit 1 2\n",
      "AZ 340 Developer 0 4\n",
      "Adapter with External SM1 Threads and Internal C-Mount Threads 9.1mm Spacer 1 2\n",
      "C-Mount Adapter 0 2\n",
      "Complete Micropipette Kit: 4 Pipettors (0.5-10μl 10-100μl 100-1000μl 1000-5000μl); Pipette Stand; 3 Racks of 96 Sterile Pipette Tips 0 2\n",
      "DB15 Male and Plastic Hoods 0 2\n",
      "Double Sided PCB Board Prototype Kit 0 2\n",
      "Foam Swab Lint Free Cleaning Swabsticks for Camera Optical Lens Electronics Detailing Small Hole 0 2\n",
      "InGaAs Switchable Gain Detector on PCB 800 - 1700 nm 11 MHz 3.14 mm2 0 2\n",
      "InGaAs Switchable Gain Detector on PCB 900 - 1700 nm 13 MHz 0.8 mm2 0 2\n",
      "Infrasil Windows 5 4\n",
      "MOTORplate 1 2\n",
      "Optical Chopper System 0 2\n",
      "Quartz Tungsten-Halogen Lamp 8-32 Tap 1 2\n",
      "Right-Angle Kinematic Elliptical Mirror Mount with Smooth Cage Rod Bores 30 mm Cage System and SM1 Compatible 8-32 and 1/4\"-20 Mounting Holes 0 2\n",
      "SM1-Threaded 30mm Cage Plate 0.50\" Thick 2 retaining rings 8-32 Tap 1 2\n",
      "Sigma Electric 14345 2-Gang Duplex Cover Grey  Gray 3 2\n",
      "Step-on Stainless Steel Trash Cans 1 2\n",
      "T-Slotted Framing Single Four Slot Rail Black 1\" High x 1\" Wide Solid 2 3\n",
      "Uline Towels for Hands-Free or Auto Dispenser - 8\" x 600' 6 4\n",
      "Wafer Carrier Tray for 2.5\"/63mm Single Wafer Natural Polypropylene 0 2\n"
     ]
    }
   ],
   "source": [
    "dupes_df = pd.read_csv(r'./duplicate_date_fixes.csv')\n",
    "print(dupes_df.columns.values)\n",
    "dupes_desc = [str(s) for s in dupes_df['description'].values]\n",
    "print(len(dupes_desc))\n",
    "dupes_desc.sort()\n",
    "\n",
    "found = 0\n",
    "for dupe in dupes_desc:\n",
    "    rows = df.loc[df['description'] == dupe].values\n",
    "    records = Purchase.objects.filter(description=dupe)\n",
    "    i = min(len(rows), len(records))\n",
    "    ## if len(rows) > 0:\n",
    "    ##     for j in range(i):\n",
    "    ##         records[j].requested = make_aware(datetime.strptime(rows[j][1], \"%m/%d/%Y\"))\n",
    "    ##         records[j].save()\n",
    "    if len(rows) != len(records):\n",
    "        print(dupe, len(rows), len(records))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5028/5028 [04:11<00:00, 20.02it/s]\n"
     ]
    }
   ],
   "source": [
    "n_rows, n_cols = df.shape\n",
    "purchases = Purchase.objects.filter(group__isnull=True).order_by('requested')\n",
    "\n",
    "for row in tqdm(range(n_rows)):\n",
    "    try:\n",
    "        p_objs = purchases.filter(description=df['description'][row])\n",
    "        if len(p_objs) > 0:\n",
    "            p_obj = p_objs[0]\n",
    "            p_obj.group = all_groups.get(group_code=df['group_id'][row])\n",
    "            p_obj.save()\n",
    "            purchases = Purchase.objects.filter(group__isnull=True).order_by('requested')\n",
    "        #print(p_obj.group, df['group_id'][row])\n",
    "        #print(f\"[LOG] ---> found object {p_obj}\")\n",
    "\n",
    "    except MultipleObjectsReturned as ex:\n",
    "        #try:\n",
    "            #v_obj = all_vendors.get(description=df['description'][row])\n",
    "            #print(f\"[LOG] ---> found object {p_obj}\")\n",
    "        #except:\n",
    "        print(f\"[ERR] {ex} ---> {df['description'][row]}\")\n",
    "    except Exception as ex:\n",
    "        print(f\"[ERR] {ex} ---> {df['description'][row]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9a31608ab0afb6106b103885e5e53a395ed23843c8eba78daefa9379a753e79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
